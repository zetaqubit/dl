{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOP1rmE7lXzXdu8ijofSPZq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zetaqubit/dl/blob/main/dl/colabs/jax_gpt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Overview\n",
        "\n",
        "This notebook implements GPT-2 and the LM training objective in pure Jax."
      ],
      "metadata": {
        "id": "3n8Jq_nkF29l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "dxg25hTjCLyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops\n",
        "!pip install transformers  # for GPT2Tokenizer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV1T-7vmkef0",
        "outputId": "6761738b-5172-4e85-e53a-fddbc913baeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.11.17)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import chex\n",
        "from chex import dataclass\n",
        "from einops import rearrange\n",
        "from dataclasses import field\n",
        "from functools import partial\n",
        "import jax\n",
        "from jax.experimental.host_callback import id_print\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "from pprint import pprint\n",
        "from typing import Any\n",
        "\n",
        "import tensorflow_datasets as tfds\n",
        "import tensorflow.compat.v2 as tf\n",
        "tf.enable_v2_behavior()"
      ],
      "metadata": {
        "id": "EBzDfGypCO8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.tools.colab_tpu\n",
        "jax.tools.colab_tpu.setup_tpu()"
      ],
      "metadata": {
        "id": "N0FzPt7ek_FD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_DEVICES = len(jax.local_devices())\n",
        "N_DEVICES"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tw-rdt0b72SA",
        "outputId": "4492b8f5-021d-41f8-f230-03612df2fc37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "e_TcafRDCwBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 512\n",
        "MAX_SEQ_LEN = 256"
      ],
      "metadata": {
        "id": "ZpXCN6-1Cwuj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizer"
      ],
      "metadata": {
        "id": "2Pn8dn6tC2jJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2', pad_token='[PAD]')"
      ],
      "metadata": {
        "id": "y4PK5RxjC4X5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenizer_encode(text, pad=False, return_masks=False):\n",
        "  if pad:\n",
        "    out = tokenizer(text,\n",
        "                    return_tensors='tf',  # pytorch not supported internally. np also fails.\n",
        "                    max_length=MAX_SEQ_LEN+1,  # +1 so target is MAX_SEQ_LEN\n",
        "                    padding='max_length',\n",
        "                    truncation=True)\n",
        "  else:\n",
        "    out = tokenizer(text, return_tensors='tf')\n",
        "  if return_masks:\n",
        "    return out\n",
        "  return out['input_ids']\n",
        "\n",
        "def tokenizer_decode(token_ids):\n",
        "  if len(token_ids.shape) == 1:\n",
        "    token_ids = token_ids[None, ...]\n",
        "  return tokenizer.batch_decode(tf.convert_to_tensor(token_ids))"
      ],
      "metadata": {
        "id": "xJTJSL8XDR3B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = tokenizer.vocab_size\n",
        "token_ids = tokenizer(['hello world', 'hi'], return_tensors='tf', max_length=10,\n",
        "                      padding='max_length', truncation=True)['input_ids']\n",
        "recovered = tokenizer.batch_decode(token_ids)\n",
        "VOCAB_SIZE, token_ids, recovered"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rW6Q6aMD59w",
        "outputId": "297f2e3d-33fb-4d61-fcbb-8c2af4d44233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50257,\n",
              " <tf.Tensor: shape=(2, 10), dtype=int32, numpy=\n",
              " array([[31373,   995, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "         50257],\n",
              "        [ 5303, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "         50257]], dtype=int32)>,\n",
              " ['hello world[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]',\n",
              "  'hi[PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD][PAD]'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_encode(['hello there', 'hi, how are you'], pad=True, return_masks=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXbd0nubEKZ_",
        "outputId": "769b4f4d-93fc-4a93-bde4-94d4557acbbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': <tf.Tensor: shape=(2, 257), dtype=int32, numpy=\n",
              "array([[31373,   612, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257],\n",
              "       [ 5303,    11,   703,   389,   345, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257, 50257,\n",
              "        50257, 50257, 50257, 50257, 50257]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 257), dtype=int32, numpy=\n",
              "array([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "       [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=int32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Grain\n",
        "https://github.com/google/grain"
      ],
      "metadata": {
        "id": "CJzqOrNiEc25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import grain.python as grain\n",
        "\n",
        "class FilterShortText(grain.FilterTransform):\n",
        "  def filter(self, element):\n",
        "    text = element['text']\n",
        "    return len(text) > 100\n",
        "\n",
        "class TokenizeTransform(grain.MapTransform):\n",
        "  def map(self, element):\n",
        "    text = element['text']\n",
        "    text = text.decode('utf-8')\n",
        "    text = text[:10 * MAX_SEQ_LEN]  # optimization to not tokenize what would be truncated anyway\n",
        "    output = tokenizer_encode(text, pad=True, return_masks=True)\n",
        "    ids = output['input_ids'].numpy()[0]\n",
        "    mask = output['attention_mask'].numpy()[0]\n",
        "    ids_input, ids_target = ids[:-1], ids[1:]\n",
        "    return ids_input, ids_target, mask\n",
        "\n",
        "operations = [\n",
        "    FilterShortText(),\n",
        "    TokenizeTransform(),\n",
        "    grain.Batch(BATCH_SIZE, drop_remainder=True),\n",
        "]"
      ],
      "metadata": {
        "id": "dxwKYDteEjs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These options allow the TPUs to not be input-bound\n",
        "# https://xprof.corp.google.com/trace_viewer/zhaoxu-3071358305372025835\n",
        "def create_pygrain_loader(ds_name, split):\n",
        "  ds = tfds.data_source(ds_name, split=split)\n",
        "  print(f'Number of records: {len(ds)} in {split}')\n",
        "  dataloader = grain.load(\n",
        "      source=ds,\n",
        "      num_epochs=None,\n",
        "      shuffle=True,\n",
        "      seed=0,\n",
        "      shard_options=grain.ShardOptions(shard_index=0, shard_count=1, drop_remainder=True),\n",
        "      transformations=operations,\n",
        "      worker_count=64,\n",
        "      read_options=grain.ReadOptions(num_threads=1, prefetch_buffer_size=32),\n",
        "  )\n",
        "  return dataloader"
      ],
      "metadata": {
        "id": "A_aveDSWFLPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DS_NAME = (\n",
        "#    'hugginface:wikitext/wikitext-103-raw-v1'\n",
        "    'c4/en'\n",
        ")\n",
        "dataloader_train = create_pygrain_loader(DS_NAME, 'train')\n",
        "dataloader_valid = create_pygrain_loader(DS_NAME, 'validation')"
      ],
      "metadata": {
        "id": "A8EosWjYFp6l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(dataloader_train))"
      ],
      "metadata": {
        "id": "zlK7ngr2GzyR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One Batch\n",
        "\n",
        "Debug dataset that repeats 1 batch of a real dataset. Models trained on this should reach 0 train loss quickly."
      ],
      "metadata": {
        "id": "Q8aIvkrNF_xk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneBatchDataset:\n",
        "  def __init__(self, batch, ex_ids, batch_size):\n",
        "    n = len(ex_ids)\n",
        "    assert n <= batch_size\n",
        "    assert batch_size % n == 0\n",
        "    self.batch = tuple(map(lambda x: np.tile(x[ex_ids], (batch_size // n, 1)), batch))\n",
        "\n",
        "  def as_numpy_iterator(self):\n",
        "    while True:\n",
        "      yield self.batch\n",
        "\n",
        "  def __iter__(self):\n",
        "    while True:\n",
        "      yield self.batch"
      ],
      "metadata": {
        "id": "8eosOAkUGLKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_IDXS = np.arange(256)\n",
        "ds_one_batch = OneBatchDataset(batch, BATCH_IDXS, BATCH_SIZE)\n",
        "one_batch = next(iter(ds_one_batch))"
      ],
      "metadata": {
        "id": "tsDZF7mpGtTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Jax Model"
      ],
      "metadata": {
        "id": "0VkokzB3IX_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def large_negative_num(dtype):\n",
        "  if jnp.issubdtype(dtype, jnp.inexact):\n",
        "    dtype_max = jnp.finfo(dtype).max\n",
        "  elif jnp.issubdtype(dtype, jnp.integer):\n",
        "    dtype_max = jnp.iinfo(dtype).max\n",
        "  else:\n",
        "    raise ValueError(f'Unknown dtype {dtype}')\n",
        "  return jnp.asarray(-0.7 * dtype_max, dtype=dtype)\n",
        "\n",
        "large_negative_num(jnp.float32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeD-M-CjIZ1J",
        "outputId": "9632a93a-6487-4945-9cb2-0e5a8c4c30c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray(-2.3819763e+38, dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "key = jax.random.PRNGKey(1)\n",
        "\n",
        "# dtype for parameters\n",
        "w_dtype = (\n",
        "    # jnp.bfloat16\n",
        "    jnp.float32\n",
        ")\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Embeddings:\n",
        "  weight: jax.Array\n",
        "\n",
        "  @staticmethod\n",
        "  def create(key, vocab_size, dim):\n",
        "    key, key_w = jax.random.split(key, 2)\n",
        "    #scale = np.sqrt(2 / dim)\n",
        "    scale = 0.02\n",
        "    weight = (scale * jax.random.normal(key_w, (vocab_size, dim))).astype(w_dtype)\n",
        "    return Embeddings(weight=weight)\n",
        "\n",
        "  def __call__(self, x):  # [b, t] -> [b, t, d]\n",
        "    return self.weight[x]\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class SinusoidalPositionEmbeddings:\n",
        "  weight: jax.Array\n",
        "\n",
        "  @staticmethod\n",
        "  def create(max_seq_len, dim):\n",
        "    pos = jnp.arange(max_seq_len)  # [s]\n",
        "    inv_freq = 1. / (10000. ** (jnp.arange(0, dim, 2) / dim))  # [d]\n",
        "    pos_emb = jnp.einsum('s, d -> s d', pos, inv_freq)\n",
        "    embs = jnp.zeros((1, max_seq_len, dim))\n",
        "    embs = embs.at[0, :, 0::2].set(jnp.sin(pos_emb))\n",
        "    embs = embs.at[0, :, 1::2].set(jnp.cos(pos_emb))\n",
        "    return SinusoidalPositionEmbeddings(weight=embs)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return self.weight\n",
        "\n",
        "  @staticmethod\n",
        "  def _flatten(self):\n",
        "    return ((),  # these are trainable\n",
        "            (self.weight,))  # these are not trainable; tag-along data\n",
        "\n",
        "  @staticmethod\n",
        "  def _unflatten(aux_data, flat_contents):\n",
        "    weight, = aux_data\n",
        "    return SinusoidalPositionEmbeddings(weight=weight)\n",
        "\n",
        "jax.tree_util.register_pytree_node(SinusoidalPositionEmbeddings,\n",
        "                                   SinusoidalPositionEmbeddings._flatten,\n",
        "                                   SinusoidalPositionEmbeddings._unflatten)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Linear:\n",
        "  weight: jax.Array\n",
        "  bias: jax.Array\n",
        "\n",
        "  @staticmethod\n",
        "  def create(key, in_dim, out_dim, sigma=0.02):\n",
        "    key, key_w = jax.random.split(key, 2)\n",
        "    #sigma = np.sqrt(2 / in_dim)\n",
        "    weight = sigma * jax.random.normal(key_w, (in_dim, out_dim), dtype=w_dtype)\n",
        "    bias = jnp.zeros((out_dim,), dtype=w_dtype)\n",
        "    return Linear(weight=weight, bias=bias)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return x @ self.weight + self.bias\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class MLP:\n",
        "  layers: list[Linear]\n",
        "\n",
        "  @staticmethod\n",
        "  def create(key, layer_widths, sigmas=None):\n",
        "    key, *keys = jax.random.split(key, len(layer_widths))\n",
        "    if sigmas is None:\n",
        "      sigmas = [0.02 for _ in layer_widths[1:]]\n",
        "      layers = [\n",
        "          Linear.create(key=k, in_dim=in_dim, out_dim=out_dim, sigma=sigma)\n",
        "          for k, in_dim, out_dim, sigma\n",
        "          in zip(keys, layer_widths[:-1], layer_widths[1:], sigmas)\n",
        "      ]\n",
        "      return MLP(layers=layers)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    for i, layer in enumerate(self.layers):\n",
        "      x = layer(x)\n",
        "      if i < len(self.layers) - 1:\n",
        "        x = jax.nn.gelu(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class MultiHeadSelfAttention:\n",
        "  to_q: Linear\n",
        "  to_k: Linear\n",
        "  to_v: Linear\n",
        "  to_out: Linear\n",
        "  heads: int\n",
        "  scale: float\n",
        "  causal: bool\n",
        "\n",
        "  @staticmethod\n",
        "  def create(key, dim, heads, causal=True, to_out_sigma=0.02):\n",
        "    assert dim % heads == 0\n",
        "    key, *keys = jax.random.split(key, 5)\n",
        "    to_q = Linear.create(key=keys[0], in_dim=dim, out_dim=dim)\n",
        "    to_k = Linear.create(key=keys[1], in_dim=dim, out_dim=dim)\n",
        "    to_v = Linear.create(key=keys[2], in_dim=dim, out_dim=dim)\n",
        "    to_out = Linear.create(key=keys[3], in_dim=dim, out_dim=dim, sigma=to_out_sigma)\n",
        "    return MultiHeadSelfAttention(\n",
        "        to_q=to_q, to_k=to_k, to_v=to_v, to_out=to_out,\n",
        "        heads=heads,\n",
        "        scale=dim ** -0.5,\n",
        "        causal=causal)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    q = self.to_q(x)\n",
        "    k = self.to_k(x)\n",
        "    v = self.to_v(x)\n",
        "    q = rearrange(q, 'b i (h d) -> b h i d', h=self.heads)\n",
        "    k = rearrange(k, 'b j (h d) -> b h j d', h=self.heads)\n",
        "    v = rearrange(v, 'b j (h d) -> b h j d', h=self.heads)\n",
        "\n",
        "    dots = self.scale * jnp.einsum('b h i d, b h j d -> b h i j', q, k)\n",
        "    j = dots.shape[-1]\n",
        "    mask = jnp.ones((j, j))\n",
        "    if self.causal:\n",
        "      mask = jnp.tril(mask, k=0)\n",
        "      dots = jnp.where(mask, dots, large_negative_num(dots.dtype))\n",
        "    dots = dots.astype(jnp.float32)\n",
        "    attn = jax.nn.softmax(dots, axis=-1)\n",
        "    outs = jnp.einsum('b h i j, b h j d -> b h i d', attn, v)\n",
        "    outs = rearrange(outs, 'b h i d -> b i (h d)')\n",
        "    out = self.to_out(outs)\n",
        "    return out\n",
        "\n",
        "  @staticmethod\n",
        "  def _flatten(self):\n",
        "    return (\n",
        "        [self.to_q, self.to_k, self.to_v, self.to_out],  # trainable\n",
        "        (self.heads, self.scale, self.causal),  # non-trainable\n",
        "    )\n",
        "\n",
        "  @staticmethod\n",
        "  def _unflatten(aux_data, flat_contents):\n",
        "    heads, scale, causal = aux_data\n",
        "    to_q, to_k, to_v, to_out = flat_contents\n",
        "    return MultiHeadSelfAttention(\n",
        "        to_q=to_q, to_k=to_k, to_v=to_v, to_out=to_out,\n",
        "        heads=heads, scale=scale, causal=causal)\n",
        "\n",
        "jax.tree_util.register_pytree_node(MultiHeadSelfAttention,\n",
        "                                   MultiHeadSelfAttention._flatten,\n",
        "                                   MultiHeadSelfAttention._unflatten)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class LayerNorm:\n",
        "  gamma: jax.Array  # shape []\n",
        "  beta: jax.Array  # shape []\n",
        "\n",
        "  @staticmethod\n",
        "  def create():\n",
        "    gamma = jnp.array([1.0])\n",
        "    beta = jnp.array([0.0])\n",
        "    return LayerNorm(gamma=gamma, beta=beta)\n",
        "\n",
        "  def __call__(self, x, mask):\n",
        "    reduce_axes = [1, 2]\n",
        "    mu = jnp.mean(x, axis=reduce_axes, where=mask[:, :, None])\n",
        "    sigma = jnp.var(x, axis=reduce_axes, where=mask[:, :, None])\n",
        "    x -= jnp.expand_dims(mu, reduce_axes)\n",
        "    x /= jnp.sqrt(jnp.expand_dims(sigma, reduce_axes) + 1e-5)\n",
        "    x *= self.gamma\n",
        "    x += self.beta\n",
        "    return x\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class TransformerBlock:\n",
        "  mhsa: MultiHeadSelfAttention\n",
        "  mlp: MLP\n",
        "  ln1: LayerNorm\n",
        "  ln2: LayerNorm\n",
        "\n",
        "  @staticmethod\n",
        "  def create(key, dim, heads, causal=True, to_out_sigma=0.02):\n",
        "    key, *keys = jax.random.split(key, 3)\n",
        "    mhsa = MultiHeadSelfAttention.create(key=keys[0], dim=dim, heads=heads,\n",
        "                                         causal=causal, to_out_sigma=to_out_sigma)\n",
        "    mlp = MLP.create(key=keys[1], layer_widths=[dim, 4*dim, dim])\n",
        "    ln1 = LayerNorm.create()\n",
        "    ln2 = LayerNorm.create()\n",
        "    return TransformerBlock(mhsa=mhsa, mlp=mlp, ln1=ln1, ln2=ln2)\n",
        "\n",
        "  def __call__(self, x, mask):\n",
        "    x = x + self.mhsa(self.ln1(x, mask))\n",
        "    x = x + self.mlp(self.ln2(x, mask))\n",
        "    return x\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class DecoderLM:\n",
        "  embeddings: Embeddings\n",
        "  pos_embs: SinusoidalPositionEmbeddings\n",
        "  layers: list[TransformerBlock]\n",
        "\n",
        "  @staticmethod\n",
        "  def create(key, vocab_size, num_layers, dim, heads, max_seq_len, causal=True):\n",
        "    key_emb, *keys = jax.random.split(key, 1 + num_layers)\n",
        "    embeddings = Embeddings.create(key=key_emb, vocab_size=vocab_size, dim=dim)\n",
        "    pos_embs = SinusoidalPositionEmbeddings.create(max_seq_len=max_seq_len, dim=dim)\n",
        "    to_out_sigma = 0.02 / jnp.sqrt(2 * num_layers)\n",
        "    layers = [\n",
        "        TransformerBlock.create(key=key, dim=dim, heads=heads, causal=causal,\n",
        "                                to_out_sigma=to_out_sigma)\n",
        "        for key in keys\n",
        "    ]\n",
        "    return DecoderLM(embeddings=embeddings, pos_embs=pos_embs, layers=layers)\n",
        "\n",
        "  def __call__(self, ids, mask):\n",
        "    x = self.embeddings(ids)\n",
        "    x = x + self.pos_embs(x)\n",
        "    for layer in self.layers:\n",
        "      x = layer(x, mask)\n",
        "    logits = jnp.einsum('b t d, v d -> b t v', x, self.embeddings.weight) # weight-tied\n",
        "    logits = jax.nn.log_softmax(logits, axis=-1)\n",
        "    return logits"
      ],
      "metadata": {
        "id": "NJ4RsdYCI0eD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test Embeddings"
      ],
      "metadata": {
        "id": "RZoSouZ4wBuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "e = Embeddings.create(key, 10, 4)\n",
        "e.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oa5pBm5wCuq",
        "outputId": "30253c0c-dcd8-44f6-c19e-9efe19ee4fbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[ 0.03750895,  0.00549101,  0.00389322,  0.00697418],\n",
              "             [-0.01988814, -0.02088845,  0.00778638,  0.0374402 ],\n",
              "             [ 0.00123927, -0.02986206,  0.01526473, -0.00770232],\n",
              "             [ 0.01272262,  0.02110806, -0.01728175,  0.02800979],\n",
              "             [ 0.02787162,  0.01041684, -0.00965307, -0.01007956],\n",
              "             [ 0.01769945,  0.02692778, -0.00219425, -0.01662124],\n",
              "             [ 0.00257271,  0.02842328,  0.01239705, -0.01502093],\n",
              "             [ 0.0147513 ,  0.0002176 ,  0.01646794, -0.00191767],\n",
              "             [-0.00169041, -0.02123914, -0.00037333,  0.00105569],\n",
              "             [-0.00892678, -0.0027822 ,  0.00409518,  0.00156941]],            dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids = jnp.array([[1, 2, 3], [4, 5, 6]])\n",
        "e(ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vPIBOi9wGcr",
        "outputId": "cfa4b0ac-88ee-4333-bfc9-f5da97262d10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[[-0.01988814, -0.02088845,  0.00778638,  0.0374402 ],\n",
              "              [ 0.00123927, -0.02986206,  0.01526473, -0.00770232],\n",
              "              [ 0.01272262,  0.02110806, -0.01728175,  0.02800979]],\n",
              "\n",
              "             [[ 0.02787162,  0.01041684, -0.00965307, -0.01007956],\n",
              "              [ 0.01769945,  0.02692778, -0.00219425, -0.01662124],\n",
              "              [ 0.00257271,  0.02842328,  0.01239705, -0.01502093]]],            dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_embeddings(e, ids):\n",
        "  return e(ids).mean()\n",
        "\n",
        "jax.value_and_grad(loss_embeddings)(e, ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9KWffjlwKt4",
        "outputId": "163a9523-8668-4aee-862e-43d0a8af3f10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(DeviceArray(0.00419533, dtype=float32),\n",
              " Embeddings(weight=DeviceArray([[0.        , 0.        , 0.        , 0.        ],\n",
              "              [0.04166667, 0.04166667, 0.04166667, 0.04166667],\n",
              "              [0.04166667, 0.04166667, 0.04166667, 0.04166667],\n",
              "              [0.04166667, 0.04166667, 0.04166667, 0.04166667],\n",
              "              [0.04166667, 0.04166667, 0.04166667, 0.04166667],\n",
              "              [0.04166667, 0.04166667, 0.04166667, 0.04166667],\n",
              "              [0.04166667, 0.04166667, 0.04166667, 0.04166667],\n",
              "              [0.        , 0.        , 0.        , 0.        ],\n",
              "              [0.        , 0.        , 0.        , 0.        ],\n",
              "              [0.        , 0.        , 0.        , 0.        ]],            dtype=float32)))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test PositionEmbeddings"
      ],
      "metadata": {
        "id": "eXhuwbn9wS50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sin_embs = SinusoidalPositionEmbeddings.create(128, 6)\n",
        "sin_embs.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqV9eVWKwUVC",
        "outputId": "ff7b29b1-cbf9-4883-df4f-d835331a63b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[[ 0.        ,  1.        ,  0.        ,  1.        ,\n",
              "                0.        ,  1.        ],\n",
              "              [ 0.84147096,  0.5403023 ,  0.04639928,  0.998923  ,\n",
              "                0.00215443,  0.9999977 ],\n",
              "              [ 0.9092974 , -0.41614684,  0.09269861,  0.9956942 ,\n",
              "                0.00430886,  0.9999907 ],\n",
              "              [ 0.14112003, -0.9899925 ,  0.13879827,  0.9903207 ,\n",
              "                0.00646326,  0.99997914],\n",
              "              [-0.7568025 , -0.6536436 ,  0.18459894,  0.98281395,\n",
              "                0.00861763,  0.99996287],\n",
              "              [-0.9589243 ,  0.2836622 ,  0.23000199,  0.9731902 ,\n",
              "                0.01077197,  0.999942  ],\n",
              "              [-0.27941552,  0.9601703 ,  0.2749096 ,  0.9614701 ,\n",
              "                0.01292625,  0.99991643],\n",
              "              [ 0.6569866 ,  0.75390226,  0.319225  ,  0.947679  ,\n",
              "                0.01508048,  0.9998863 ],\n",
              "              [ 0.98935825, -0.14550005,  0.3628528 ,  0.9318465 ,\n",
              "                0.01723463,  0.99985147],\n",
              "              [ 0.4121185 , -0.91113025,  0.40569904,  0.9140067 ,\n",
              "                0.0193887 ,  0.999812  ],\n",
              "              [-0.5440211 , -0.8390715 ,  0.44767132,  0.8941982 ,\n",
              "                0.02154269,  0.99976796],\n",
              "              [-0.9999902 ,  0.0044257 ,  0.4886793 ,  0.87246346,\n",
              "                0.02369657,  0.9997192 ],\n",
              "              [-0.536573  ,  0.8438539 ,  0.52863467,  0.8488494 ,\n",
              "                0.02585034,  0.9996658 ],\n",
              "              [ 0.42016706,  0.9074468 ,  0.5674513 ,  0.82340693,\n",
              "                0.028004  ,  0.9996078 ],\n",
              "              [ 0.9906074 ,  0.13673723,  0.6050457 ,  0.7961908 ,\n",
              "                0.03015752,  0.99954516],\n",
              "              [ 0.65028787, -0.7596879 ,  0.6413367 ,  0.7672596 ,\n",
              "                0.0323109 ,  0.99947786],\n",
              "              [-0.28790334, -0.95765954,  0.6762462 ,  0.7366757 ,\n",
              "                0.03446414,  0.9994059 ],\n",
              "              [-0.9613975 , -0.27516332,  0.70969903,  0.70450497,\n",
              "                0.03661721,  0.9993294 ],\n",
              "              [-0.75098723,  0.66031677,  0.74162334,  0.6708166 ,\n",
              "                0.03877012,  0.99924815],\n",
              "              [ 0.1498772 ,  0.9887046 ,  0.7719499 ,  0.63568336,\n",
              "                0.04092284,  0.9991623 ],\n",
              "              [ 0.9129453 ,  0.4080821 ,  0.80061376,  0.5991808 ,\n",
              "                0.04307537,  0.99907184],\n",
              "              [ 0.8366556 , -0.54772925,  0.82755303,  0.56138754,\n",
              "                0.04522771,  0.9989767 ],\n",
              "              [-0.00885131, -0.99996084,  0.85270965,  0.52238506,\n",
              "                0.04737983,  0.9988769 ],\n",
              "              [-0.8462204 , -0.53283304,  0.8760296 ,  0.4822573 ,\n",
              "                0.04953174,  0.99877256],\n",
              "              [-0.9055784 ,  0.42417905,  0.8974625 ,  0.44109073,\n",
              "                0.05168341,  0.99866354],\n",
              "              [-0.13235176,  0.99120283,  0.9169622 ,  0.39897406,\n",
              "                0.05383484,  0.9985499 ],\n",
              "              [ 0.76255846,  0.6469193 ,  0.93448675,  0.355998  ,\n",
              "                0.05598603,  0.99843156],\n",
              "              [ 0.95637596, -0.29213884,  0.9499983 ,  0.31225508,\n",
              "                0.05813695,  0.9983086 ],\n",
              "              [ 0.2709058 , -0.9626059 ,  0.96346354,  0.26783955,\n",
              "                0.06028761,  0.99818105],\n",
              "              [-0.6636339 , -0.74805754,  0.97485346,  0.22284697,\n",
              "                0.06243799,  0.99804884],\n",
              "              [-0.9880316 ,  0.15425146,  0.98414344,  0.17737448,\n",
              "                0.06458807,  0.997912  ],\n",
              "              [-0.40403765,  0.91474235,  0.9913135 ,  0.13151991,\n",
              "                0.06673785,  0.99777055],\n",
              "              [ 0.5514267 ,  0.83422333,  0.9963483 ,  0.08538205,\n",
              "                0.06888733,  0.99762446],\n",
              "              [ 0.99991184, -0.01327675,  0.9992369 ,  0.03906027,\n",
              "                0.07103648,  0.9974737 ],\n",
              "              [ 0.5290827 , -0.8485702 ,  0.999973  , -0.00734565,\n",
              "                0.07318531,  0.9973184 ],\n",
              "              [-0.42818266, -0.9036922 ,  0.9985552 , -0.05373575,\n",
              "                0.07533379,  0.9971584 ],\n",
              "              [-0.99177885, -0.12796369,  0.9949864 , -0.10001023,\n",
              "                0.07748194,  0.9969938 ],\n",
              "              [-0.6435382 ,  0.76541406,  0.9892744 , -0.14606914,\n",
              "                0.07962971,  0.9968245 ],\n",
              "              [ 0.29636857,  0.9550737 ,  0.9814314 , -0.19181342,\n",
              "                0.08177712,  0.99665064],\n",
              "              [ 0.9637954 ,  0.26664296,  0.9714744 , -0.23714453,\n",
              "                0.08392414,  0.9964722 ],\n",
              "              [ 0.7451132 , -0.66693807,  0.9594248 , -0.2819648 ,\n",
              "                0.08607078,  0.996289  ],\n",
              "              [-0.15862267, -0.9873393 ,  0.9453085 , -0.32617775,\n",
              "                0.08821703,  0.99610126],\n",
              "              [-0.91652155, -0.39998534,  0.92915595, -0.36968812,\n",
              "                0.09036285,  0.9959089 ],\n",
              "              [-0.8317747 ,  0.5551133 ,  0.9110019 , -0.41240215,\n",
              "                0.09250826,  0.9957119 ],\n",
              "              [ 0.01770193,  0.9998433 ,  0.8908856 , -0.4542277 ,\n",
              "                0.09465324,  0.99551034],\n",
              "              [ 0.8509035 ,  0.525322  ,  0.86885023, -0.495075  ,\n",
              "                0.09679778,  0.9953041 ],\n",
              "              [ 0.90178835, -0.432178  ,  0.8449433 , -0.5348559 ,\n",
              "                0.09894188,  0.9950932 ],\n",
              "              [ 0.12357312, -0.9923355 ,  0.8192164 , -0.5734845 ,\n",
              "                0.10108551,  0.99487776],\n",
              "              [-0.76825464, -0.6401444 ,  0.7917248 , -0.610878  ,\n",
              "                0.10322867,  0.99465764],\n",
              "              [-0.9537527 ,  0.30059254,  0.7625279 , -0.64695543,\n",
              "                0.10537136,  0.9944329 ],\n",
              "              [-0.26237485,  0.96496606,  0.73168826, -0.6816394 ,\n",
              "                0.10751355,  0.9942036 ],\n",
              "              [ 0.6702292 ,  0.74215424,  0.69927275, -0.71485496,\n",
              "                0.10965525,  0.9939697 ],\n",
              "              [ 0.98662764, -0.16299078,  0.6653508 , -0.7465309 ,\n",
              "                0.11179643,  0.99373114],\n",
              "              [ 0.39592513, -0.9182828 ,  0.62999564, -0.7765987 ,\n",
              "                0.1139371 ,  0.99348795],\n",
              "              [-0.55878913, -0.82930976,  0.5932836 , -0.8049935 ,\n",
              "                0.11607724,  0.9932402 ],\n",
              "              [-0.99975514,  0.02212676,  0.5552934 , -0.83165455,\n",
              "                0.11821684,  0.9929878 ],\n",
              "              [-0.521551  ,  0.8532201 ,  0.5161073 , -0.85652393,\n",
              "                0.1203559 ,  0.9927308 ],\n",
              "              [ 0.43616474,  0.8998668 ,  0.47580925, -0.8795485 ,\n",
              "                0.12249439,  0.9924692 ],\n",
              "              [ 0.99287266,  0.11918014,  0.43448627, -0.90067846,\n",
              "                0.12463231,  0.992203  ],\n",
              "              [ 0.636738  , -0.77108026,  0.39222762, -0.91986823,\n",
              "                0.12676965,  0.9919322 ],\n",
              "              [-0.3048106 , -0.952413  ,  0.34912384, -0.9370766 ,\n",
              "                0.12890641,  0.9916568 ],\n",
              "              [-0.9661178 , -0.25810164,  0.3052683 , -0.95226645,\n",
              "                0.13104257,  0.99137676],\n",
              "              [-0.7391807 ,  0.6735072 ,  0.26075494, -0.96540505,\n",
              "                0.13317813,  0.99109215],\n",
              "              [ 0.16735572,  0.9858966 ,  0.21568015, -0.9764641 ,\n",
              "                0.13531305,  0.9908029 ],\n",
              "              [ 0.92002606,  0.39185724,  0.17014052, -0.9854198 ,\n",
              "                0.13744736,  0.9905091 ],\n",
              "              [ 0.82682866, -0.56245387,  0.12423441, -0.9922529 ,\n",
              "                0.13958104,  0.99021065],\n",
              "              [-0.02655115, -0.99964744,  0.07806092, -0.9969486 ,\n",
              "                0.14171404,  0.9899077 ],\n",
              "              [-0.85551995, -0.5177698 ,  0.03171905, -0.9994968 ,\n",
              "                0.14384641,  0.98960006],\n",
              "              [-0.89792764,  0.44014305, -0.01469091, -0.99989206,\n",
              "                0.14597811,  0.98928785],\n",
              "              [-0.11478481,  0.9933904 , -0.06106947, -0.99813354,\n",
              "                0.14810912,  0.98897105],\n",
              "              [ 0.7738906 ,  0.63331926, -0.10731622, -0.99422497,\n",
              "                0.15023945,  0.98864967],\n",
              "              [ 0.9510547 , -0.30902272, -0.15333207, -0.98817474,\n",
              "                0.15236908,  0.9883237 ],\n",
              "              [ 0.25382337, -0.96725065, -0.19901763, -0.97999597,\n",
              "                0.15449801,  0.9879931 ],\n",
              "              [-0.67677194, -0.7361927 , -0.24427423, -0.96970624,\n",
              "                0.15662621,  0.98765796],\n",
              "              [-0.9851463 ,  0.17171735, -0.28900492, -0.95732766,\n",
              "                0.1587537 ,  0.9873182 ],\n",
              "              [-0.38778162,  0.92175126, -0.33311287, -0.942887  ,\n",
              "                0.16088043,  0.98697394],\n",
              "              [ 0.56610763,  0.8243313 , -0.3765034 , -0.92641526,\n",
              "                0.16300642,  0.986625  ],\n",
              "              [ 0.9995202 , -0.03097503, -0.419083  , -0.9079479 ,\n",
              "                0.16513167,  0.98627156],\n",
              "              [ 0.5139785 , -0.85780305, -0.46075967, -0.88752496,\n",
              "                0.16725615,  0.9859135 ],\n",
              "              [-0.4441127 , -0.89597094, -0.50144404, -0.86519   ,\n",
              "                0.16937985,  0.9855509 ],\n",
              "              [-0.9938887 , -0.11038724, -0.54104805, -0.8409916 ,\n",
              "                0.17150275,  0.98518366],\n",
              "              [-0.629888  ,  0.77668595, -0.5794867 , -0.81498164,\n",
              "                0.17362487,  0.9848119 ],\n",
              "              [ 0.3132288 ,  0.9496777 , -0.61667717, -0.7872162 ,\n",
              "                0.17574617,  0.98443556],\n",
              "              [ 0.9683645 ,  0.24954014, -0.6525393 , -0.7577549 ,\n",
              "                0.17786667,  0.9840546 ],\n",
              "              [ 0.7331903 , -0.68002355, -0.68699586, -0.72666144,\n",
              "                0.17998633,  0.98366916],\n",
              "              [-0.17607564, -0.98437667, -0.7199724 , -0.69400275,\n",
              "                0.18210517,  0.9832791 ],\n",
              "              [-0.92345846, -0.38369846, -0.75139827, -0.659849  ,\n",
              "                0.18422315,  0.98288447],\n",
              "              [-0.8218178 ,  0.56975037, -0.7812054 , -0.6242741 ,\n",
              "                0.18634029,  0.9824853 ],\n",
              "              [ 0.0353983 ,  0.99937326, -0.8093298 , -0.5873545 ,\n",
              "                0.18845655,  0.98208153],\n",
              "              [ 0.8600694 ,  0.510177  , -0.8357111 , -0.54916924,\n",
              "                0.19057196,  0.98167324],\n",
              "              [ 0.89399666, -0.44807366, -0.860292  , -0.50980157,\n",
              "                0.19268645,  0.9812604 ],\n",
              "              [ 0.10598752, -0.9943675 , -0.8830198 , -0.46933565,\n",
              "                0.19480008,  0.980843  ],\n",
              "              [-0.77946603, -0.62644446, -0.9038458 , -0.42785835,\n",
              "                0.19691278,  0.98042107],\n",
              "              [-0.9482822 ,  0.3174287 , -0.9227246 , -0.3854599 ,\n",
              "                0.19902456,  0.97999454],\n",
              "              [-0.24525198,  0.9694594 , -0.93961585, -0.34223112,\n",
              "                0.20113544,  0.9795635 ],\n",
              "              [ 0.6832617 ,  0.7301736 , -0.9544831 , -0.29826516,\n",
              "                0.20324539,  0.9791279 ],\n",
              "              [ 0.9835878 , -0.18043044, -0.96729445, -0.25365627,\n",
              "                0.20535439,  0.9786877 ],\n",
              "              [ 0.37960777, -0.92514753, -0.9780221 , -0.20850143,\n",
              "                0.20746242,  0.978243  ],\n",
              "              [-0.57338184, -0.81928825, -0.986643  , -0.1628975 ,\n",
              "                0.2095695 ,  0.9777938 ],\n",
              "              [-0.99920684,  0.03982088, -0.99313873, -0.11694218,\n",
              "                0.21167561,  0.97734004],\n",
              "              [-0.50636566,  0.8623189 , -0.9974951 , -0.07073545,\n",
              "                0.21378072,  0.9768817 ],\n",
              "              [ 0.4520258 ,  0.89200485, -0.9997029 , -0.02437635,\n",
              "                0.21588485,  0.97641885],\n",
              "              [ 0.9948268 ,  0.10158569, -0.9997572 ,  0.02203526,\n",
              "                0.21798798,  0.9759515 ],\n",
              "              [ 0.62298864, -0.78223085, -0.997658  ,  0.06839988,\n",
              "                0.22009009,  0.9754796 ],\n",
              "              [-0.3216224 , -0.94686806, -0.9934098 ,  0.11461669,\n",
              "                0.22219118,  0.9750031 ],\n",
              "              [-0.97053534, -0.24095905, -0.9870218 ,  0.1605866 ,\n",
              "                0.22429127,  0.9745222 ],\n",
              "              [-0.7271425 ,  0.68648654, -0.9785076 ,  0.20621109,\n",
              "                0.22639029,  0.9740367 ],\n",
              "              [ 0.18478175,  0.9827796 , -0.9678857 ,  0.25139087,\n",
              "                0.22848825,  0.9735467 ],\n",
              "              [ 0.9268185 ,  0.3755096 , -0.9551789 ,  0.2960292 ,\n",
              "                0.23058516,  0.9730522 ],\n",
              "              [ 0.8167426 , -0.57700217, -0.9404145 ,  0.3400303 ,\n",
              "                0.232681  ,  0.97255313],\n",
              "              [-0.04424268, -0.9990208 , -0.9236245 ,  0.3832985 ,\n",
              "                0.23477577,  0.9720496 ],\n",
              "              [-0.8645514 , -0.50254434, -0.90484506,  0.42574105,\n",
              "                0.23686944,  0.9715415 ],\n",
              "              [-0.8899956 ,  0.45596913, -0.8841165 ,  0.46726656,\n",
              "                0.23896201,  0.9710289 ],\n",
              "              [-0.09718191,  0.9952667 , -0.8614832 ,  0.5077859 ,\n",
              "                0.24105346,  0.97051185],\n",
              "              [ 0.78498036,  0.61952066, -0.8369945 ,  0.54721117,\n",
              "                0.24314381,  0.9699903 ],\n",
              "              [ 0.94543535, -0.3258098 , -0.810703  ,  0.5854577 ,\n",
              "                0.24523303,  0.9694642 ],\n",
              "              [ 0.23666139, -0.97159225, -0.78266484,  0.6224433 ,\n",
              "                0.24732111,  0.9689336 ],\n",
              "              [-0.689698  , -0.72409713, -0.752941  ,  0.658088  ,\n",
              "                0.24940804,  0.9683985 ],\n",
              "              [-0.9819522 ,  0.18912943, -0.7215954 ,  0.69231504,\n",
              "                0.25149378,  0.96785897],\n",
              "              [-0.3714041 ,  0.9284713 , -0.68869543,  0.72505075,\n",
              "                0.2535784 ,  0.9673149 ],\n",
              "              [ 0.58061117,  0.81418097, -0.6543116 ,  0.7562251 ,\n",
              "                0.25566185,  0.9667663 ],\n",
              "              [ 0.99881524, -0.04866361, -0.61851865,  0.7857701 ,\n",
              "                0.25774407,  0.9662133 ],\n",
              "              [ 0.49871314, -0.86676705, -0.5813935 ,  0.81362253,\n",
              "                0.2598251 ,  0.96565574],\n",
              "              [-0.4599035 , -0.8879689 , -0.5430155 ,  0.83972263,\n",
              "                0.26190498,  0.96509373],\n",
              "              [-0.995687  , -0.09277621, -0.5034682 ,  0.8640137 ,\n",
              "                0.26398358,  0.9645272 ],\n",
              "              [-0.6160404 ,  0.78771454, -0.46283653,  0.8864436 ,\n",
              "                0.26606098,  0.96395624],\n",
              "              [ 0.32999083,  0.94398415, -0.42120782,  0.9069641 ,\n",
              "                0.26813713,  0.9633808 ],\n",
              "              [ 0.9726301 ,  0.23235911, -0.37867135,  0.9255312 ,\n",
              "                0.27021205,  0.96280086]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_sin_embs(sin_embs, ids):\n",
        "  return -sin_embs(ids).mean()\n",
        "\n",
        "jax.value_and_grad(loss_sin_embs)(sin_embs, ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPxmy6_GwawP",
        "outputId": "e94405c7-4286-4053-a7cb-f929e18164fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(DeviceArray(-0.18322927, dtype=float32),\n",
              " SinusoidalPositionEmbeddings(weight=DeviceArray([[[ 0.        ,  1.        ,  0.        ,  1.        ,\n",
              "                 0.        ,  1.        ],\n",
              "               [ 0.84147096,  0.5403023 ,  0.04639928,  0.998923  ,\n",
              "                 0.00215443,  0.9999977 ],\n",
              "               [ 0.9092974 , -0.41614684,  0.09269861,  0.9956942 ,\n",
              "                 0.00430886,  0.9999907 ],\n",
              "               [ 0.14112003, -0.9899925 ,  0.13879827,  0.9903207 ,\n",
              "                 0.00646326,  0.99997914],\n",
              "               [-0.7568025 , -0.6536436 ,  0.18459894,  0.98281395,\n",
              "                 0.00861763,  0.99996287],\n",
              "               [-0.9589243 ,  0.2836622 ,  0.23000199,  0.9731902 ,\n",
              "                 0.01077197,  0.999942  ],\n",
              "               [-0.27941552,  0.9601703 ,  0.2749096 ,  0.9614701 ,\n",
              "                 0.01292625,  0.99991643],\n",
              "               [ 0.6569866 ,  0.75390226,  0.319225  ,  0.947679  ,\n",
              "                 0.01508048,  0.9998863 ],\n",
              "               [ 0.98935825, -0.14550005,  0.3628528 ,  0.9318465 ,\n",
              "                 0.01723463,  0.99985147],\n",
              "               [ 0.4121185 , -0.91113025,  0.40569904,  0.9140067 ,\n",
              "                 0.0193887 ,  0.999812  ],\n",
              "               [-0.5440211 , -0.8390715 ,  0.44767132,  0.8941982 ,\n",
              "                 0.02154269,  0.99976796],\n",
              "               [-0.9999902 ,  0.0044257 ,  0.4886793 ,  0.87246346,\n",
              "                 0.02369657,  0.9997192 ],\n",
              "               [-0.536573  ,  0.8438539 ,  0.52863467,  0.8488494 ,\n",
              "                 0.02585034,  0.9996658 ],\n",
              "               [ 0.42016706,  0.9074468 ,  0.5674513 ,  0.82340693,\n",
              "                 0.028004  ,  0.9996078 ],\n",
              "               [ 0.9906074 ,  0.13673723,  0.6050457 ,  0.7961908 ,\n",
              "                 0.03015752,  0.99954516],\n",
              "               [ 0.65028787, -0.7596879 ,  0.6413367 ,  0.7672596 ,\n",
              "                 0.0323109 ,  0.99947786],\n",
              "               [-0.28790334, -0.95765954,  0.6762462 ,  0.7366757 ,\n",
              "                 0.03446414,  0.9994059 ],\n",
              "               [-0.9613975 , -0.27516332,  0.70969903,  0.70450497,\n",
              "                 0.03661721,  0.9993294 ],\n",
              "               [-0.75098723,  0.66031677,  0.74162334,  0.6708166 ,\n",
              "                 0.03877012,  0.99924815],\n",
              "               [ 0.1498772 ,  0.9887046 ,  0.7719499 ,  0.63568336,\n",
              "                 0.04092284,  0.9991623 ],\n",
              "               [ 0.9129453 ,  0.4080821 ,  0.80061376,  0.5991808 ,\n",
              "                 0.04307537,  0.99907184],\n",
              "               [ 0.8366556 , -0.54772925,  0.82755303,  0.56138754,\n",
              "                 0.04522771,  0.9989767 ],\n",
              "               [-0.00885131, -0.99996084,  0.85270965,  0.52238506,\n",
              "                 0.04737983,  0.9988769 ],\n",
              "               [-0.8462204 , -0.53283304,  0.8760296 ,  0.4822573 ,\n",
              "                 0.04953174,  0.99877256],\n",
              "               [-0.9055784 ,  0.42417905,  0.8974625 ,  0.44109073,\n",
              "                 0.05168341,  0.99866354],\n",
              "               [-0.13235176,  0.99120283,  0.9169622 ,  0.39897406,\n",
              "                 0.05383484,  0.9985499 ],\n",
              "               [ 0.76255846,  0.6469193 ,  0.93448675,  0.355998  ,\n",
              "                 0.05598603,  0.99843156],\n",
              "               [ 0.95637596, -0.29213884,  0.9499983 ,  0.31225508,\n",
              "                 0.05813695,  0.9983086 ],\n",
              "               [ 0.2709058 , -0.9626059 ,  0.96346354,  0.26783955,\n",
              "                 0.06028761,  0.99818105],\n",
              "               [-0.6636339 , -0.74805754,  0.97485346,  0.22284697,\n",
              "                 0.06243799,  0.99804884],\n",
              "               [-0.9880316 ,  0.15425146,  0.98414344,  0.17737448,\n",
              "                 0.06458807,  0.997912  ],\n",
              "               [-0.40403765,  0.91474235,  0.9913135 ,  0.13151991,\n",
              "                 0.06673785,  0.99777055],\n",
              "               [ 0.5514267 ,  0.83422333,  0.9963483 ,  0.08538205,\n",
              "                 0.06888733,  0.99762446],\n",
              "               [ 0.99991184, -0.01327675,  0.9992369 ,  0.03906027,\n",
              "                 0.07103648,  0.9974737 ],\n",
              "               [ 0.5290827 , -0.8485702 ,  0.999973  , -0.00734565,\n",
              "                 0.07318531,  0.9973184 ],\n",
              "               [-0.42818266, -0.9036922 ,  0.9985552 , -0.05373575,\n",
              "                 0.07533379,  0.9971584 ],\n",
              "               [-0.99177885, -0.12796369,  0.9949864 , -0.10001023,\n",
              "                 0.07748194,  0.9969938 ],\n",
              "               [-0.6435382 ,  0.76541406,  0.9892744 , -0.14606914,\n",
              "                 0.07962971,  0.9968245 ],\n",
              "               [ 0.29636857,  0.9550737 ,  0.9814314 , -0.19181342,\n",
              "                 0.08177712,  0.99665064],\n",
              "               [ 0.9637954 ,  0.26664296,  0.9714744 , -0.23714453,\n",
              "                 0.08392414,  0.9964722 ],\n",
              "               [ 0.7451132 , -0.66693807,  0.9594248 , -0.2819648 ,\n",
              "                 0.08607078,  0.996289  ],\n",
              "               [-0.15862267, -0.9873393 ,  0.9453085 , -0.32617775,\n",
              "                 0.08821703,  0.99610126],\n",
              "               [-0.91652155, -0.39998534,  0.92915595, -0.36968812,\n",
              "                 0.09036285,  0.9959089 ],\n",
              "               [-0.8317747 ,  0.5551133 ,  0.9110019 , -0.41240215,\n",
              "                 0.09250826,  0.9957119 ],\n",
              "               [ 0.01770193,  0.9998433 ,  0.8908856 , -0.4542277 ,\n",
              "                 0.09465324,  0.99551034],\n",
              "               [ 0.8509035 ,  0.525322  ,  0.86885023, -0.495075  ,\n",
              "                 0.09679778,  0.9953041 ],\n",
              "               [ 0.90178835, -0.432178  ,  0.8449433 , -0.5348559 ,\n",
              "                 0.09894188,  0.9950932 ],\n",
              "               [ 0.12357312, -0.9923355 ,  0.8192164 , -0.5734845 ,\n",
              "                 0.10108551,  0.99487776],\n",
              "               [-0.76825464, -0.6401444 ,  0.7917248 , -0.610878  ,\n",
              "                 0.10322867,  0.99465764],\n",
              "               [-0.9537527 ,  0.30059254,  0.7625279 , -0.64695543,\n",
              "                 0.10537136,  0.9944329 ],\n",
              "               [-0.26237485,  0.96496606,  0.73168826, -0.6816394 ,\n",
              "                 0.10751355,  0.9942036 ],\n",
              "               [ 0.6702292 ,  0.74215424,  0.69927275, -0.71485496,\n",
              "                 0.10965525,  0.9939697 ],\n",
              "               [ 0.98662764, -0.16299078,  0.6653508 , -0.7465309 ,\n",
              "                 0.11179643,  0.99373114],\n",
              "               [ 0.39592513, -0.9182828 ,  0.62999564, -0.7765987 ,\n",
              "                 0.1139371 ,  0.99348795],\n",
              "               [-0.55878913, -0.82930976,  0.5932836 , -0.8049935 ,\n",
              "                 0.11607724,  0.9932402 ],\n",
              "               [-0.99975514,  0.02212676,  0.5552934 , -0.83165455,\n",
              "                 0.11821684,  0.9929878 ],\n",
              "               [-0.521551  ,  0.8532201 ,  0.5161073 , -0.85652393,\n",
              "                 0.1203559 ,  0.9927308 ],\n",
              "               [ 0.43616474,  0.8998668 ,  0.47580925, -0.8795485 ,\n",
              "                 0.12249439,  0.9924692 ],\n",
              "               [ 0.99287266,  0.11918014,  0.43448627, -0.90067846,\n",
              "                 0.12463231,  0.992203  ],\n",
              "               [ 0.636738  , -0.77108026,  0.39222762, -0.91986823,\n",
              "                 0.12676965,  0.9919322 ],\n",
              "               [-0.3048106 , -0.952413  ,  0.34912384, -0.9370766 ,\n",
              "                 0.12890641,  0.9916568 ],\n",
              "               [-0.9661178 , -0.25810164,  0.3052683 , -0.95226645,\n",
              "                 0.13104257,  0.99137676],\n",
              "               [-0.7391807 ,  0.6735072 ,  0.26075494, -0.96540505,\n",
              "                 0.13317813,  0.99109215],\n",
              "               [ 0.16735572,  0.9858966 ,  0.21568015, -0.9764641 ,\n",
              "                 0.13531305,  0.9908029 ],\n",
              "               [ 0.92002606,  0.39185724,  0.17014052, -0.9854198 ,\n",
              "                 0.13744736,  0.9905091 ],\n",
              "               [ 0.82682866, -0.56245387,  0.12423441, -0.9922529 ,\n",
              "                 0.13958104,  0.99021065],\n",
              "               [-0.02655115, -0.99964744,  0.07806092, -0.9969486 ,\n",
              "                 0.14171404,  0.9899077 ],\n",
              "               [-0.85551995, -0.5177698 ,  0.03171905, -0.9994968 ,\n",
              "                 0.14384641,  0.98960006],\n",
              "               [-0.89792764,  0.44014305, -0.01469091, -0.99989206,\n",
              "                 0.14597811,  0.98928785],\n",
              "               [-0.11478481,  0.9933904 , -0.06106947, -0.99813354,\n",
              "                 0.14810912,  0.98897105],\n",
              "               [ 0.7738906 ,  0.63331926, -0.10731622, -0.99422497,\n",
              "                 0.15023945,  0.98864967],\n",
              "               [ 0.9510547 , -0.30902272, -0.15333207, -0.98817474,\n",
              "                 0.15236908,  0.9883237 ],\n",
              "               [ 0.25382337, -0.96725065, -0.19901763, -0.97999597,\n",
              "                 0.15449801,  0.9879931 ],\n",
              "               [-0.67677194, -0.7361927 , -0.24427423, -0.96970624,\n",
              "                 0.15662621,  0.98765796],\n",
              "               [-0.9851463 ,  0.17171735, -0.28900492, -0.95732766,\n",
              "                 0.1587537 ,  0.9873182 ],\n",
              "               [-0.38778162,  0.92175126, -0.33311287, -0.942887  ,\n",
              "                 0.16088043,  0.98697394],\n",
              "               [ 0.56610763,  0.8243313 , -0.3765034 , -0.92641526,\n",
              "                 0.16300642,  0.986625  ],\n",
              "               [ 0.9995202 , -0.03097503, -0.419083  , -0.9079479 ,\n",
              "                 0.16513167,  0.98627156],\n",
              "               [ 0.5139785 , -0.85780305, -0.46075967, -0.88752496,\n",
              "                 0.16725615,  0.9859135 ],\n",
              "               [-0.4441127 , -0.89597094, -0.50144404, -0.86519   ,\n",
              "                 0.16937985,  0.9855509 ],\n",
              "               [-0.9938887 , -0.11038724, -0.54104805, -0.8409916 ,\n",
              "                 0.17150275,  0.98518366],\n",
              "               [-0.629888  ,  0.77668595, -0.5794867 , -0.81498164,\n",
              "                 0.17362487,  0.9848119 ],\n",
              "               [ 0.3132288 ,  0.9496777 , -0.61667717, -0.7872162 ,\n",
              "                 0.17574617,  0.98443556],\n",
              "               [ 0.9683645 ,  0.24954014, -0.6525393 , -0.7577549 ,\n",
              "                 0.17786667,  0.9840546 ],\n",
              "               [ 0.7331903 , -0.68002355, -0.68699586, -0.72666144,\n",
              "                 0.17998633,  0.98366916],\n",
              "               [-0.17607564, -0.98437667, -0.7199724 , -0.69400275,\n",
              "                 0.18210517,  0.9832791 ],\n",
              "               [-0.92345846, -0.38369846, -0.75139827, -0.659849  ,\n",
              "                 0.18422315,  0.98288447],\n",
              "               [-0.8218178 ,  0.56975037, -0.7812054 , -0.6242741 ,\n",
              "                 0.18634029,  0.9824853 ],\n",
              "               [ 0.0353983 ,  0.99937326, -0.8093298 , -0.5873545 ,\n",
              "                 0.18845655,  0.98208153],\n",
              "               [ 0.8600694 ,  0.510177  , -0.8357111 , -0.54916924,\n",
              "                 0.19057196,  0.98167324],\n",
              "               [ 0.89399666, -0.44807366, -0.860292  , -0.50980157,\n",
              "                 0.19268645,  0.9812604 ],\n",
              "               [ 0.10598752, -0.9943675 , -0.8830198 , -0.46933565,\n",
              "                 0.19480008,  0.980843  ],\n",
              "               [-0.77946603, -0.62644446, -0.9038458 , -0.42785835,\n",
              "                 0.19691278,  0.98042107],\n",
              "               [-0.9482822 ,  0.3174287 , -0.9227246 , -0.3854599 ,\n",
              "                 0.19902456,  0.97999454],\n",
              "               [-0.24525198,  0.9694594 , -0.93961585, -0.34223112,\n",
              "                 0.20113544,  0.9795635 ],\n",
              "               [ 0.6832617 ,  0.7301736 , -0.9544831 , -0.29826516,\n",
              "                 0.20324539,  0.9791279 ],\n",
              "               [ 0.9835878 , -0.18043044, -0.96729445, -0.25365627,\n",
              "                 0.20535439,  0.9786877 ],\n",
              "               [ 0.37960777, -0.92514753, -0.9780221 , -0.20850143,\n",
              "                 0.20746242,  0.978243  ],\n",
              "               [-0.57338184, -0.81928825, -0.986643  , -0.1628975 ,\n",
              "                 0.2095695 ,  0.9777938 ],\n",
              "               [-0.99920684,  0.03982088, -0.99313873, -0.11694218,\n",
              "                 0.21167561,  0.97734004],\n",
              "               [-0.50636566,  0.8623189 , -0.9974951 , -0.07073545,\n",
              "                 0.21378072,  0.9768817 ],\n",
              "               [ 0.4520258 ,  0.89200485, -0.9997029 , -0.02437635,\n",
              "                 0.21588485,  0.97641885],\n",
              "               [ 0.9948268 ,  0.10158569, -0.9997572 ,  0.02203526,\n",
              "                 0.21798798,  0.9759515 ],\n",
              "               [ 0.62298864, -0.78223085, -0.997658  ,  0.06839988,\n",
              "                 0.22009009,  0.9754796 ],\n",
              "               [-0.3216224 , -0.94686806, -0.9934098 ,  0.11461669,\n",
              "                 0.22219118,  0.9750031 ],\n",
              "               [-0.97053534, -0.24095905, -0.9870218 ,  0.1605866 ,\n",
              "                 0.22429127,  0.9745222 ],\n",
              "               [-0.7271425 ,  0.68648654, -0.9785076 ,  0.20621109,\n",
              "                 0.22639029,  0.9740367 ],\n",
              "               [ 0.18478175,  0.9827796 , -0.9678857 ,  0.25139087,\n",
              "                 0.22848825,  0.9735467 ],\n",
              "               [ 0.9268185 ,  0.3755096 , -0.9551789 ,  0.2960292 ,\n",
              "                 0.23058516,  0.9730522 ],\n",
              "               [ 0.8167426 , -0.57700217, -0.9404145 ,  0.3400303 ,\n",
              "                 0.232681  ,  0.97255313],\n",
              "               [-0.04424268, -0.9990208 , -0.9236245 ,  0.3832985 ,\n",
              "                 0.23477577,  0.9720496 ],\n",
              "               [-0.8645514 , -0.50254434, -0.90484506,  0.42574105,\n",
              "                 0.23686944,  0.9715415 ],\n",
              "               [-0.8899956 ,  0.45596913, -0.8841165 ,  0.46726656,\n",
              "                 0.23896201,  0.9710289 ],\n",
              "               [-0.09718191,  0.9952667 , -0.8614832 ,  0.5077859 ,\n",
              "                 0.24105346,  0.97051185],\n",
              "               [ 0.78498036,  0.61952066, -0.8369945 ,  0.54721117,\n",
              "                 0.24314381,  0.9699903 ],\n",
              "               [ 0.94543535, -0.3258098 , -0.810703  ,  0.5854577 ,\n",
              "                 0.24523303,  0.9694642 ],\n",
              "               [ 0.23666139, -0.97159225, -0.78266484,  0.6224433 ,\n",
              "                 0.24732111,  0.9689336 ],\n",
              "               [-0.689698  , -0.72409713, -0.752941  ,  0.658088  ,\n",
              "                 0.24940804,  0.9683985 ],\n",
              "               [-0.9819522 ,  0.18912943, -0.7215954 ,  0.69231504,\n",
              "                 0.25149378,  0.96785897],\n",
              "               [-0.3714041 ,  0.9284713 , -0.68869543,  0.72505075,\n",
              "                 0.2535784 ,  0.9673149 ],\n",
              "               [ 0.58061117,  0.81418097, -0.6543116 ,  0.7562251 ,\n",
              "                 0.25566185,  0.9667663 ],\n",
              "               [ 0.99881524, -0.04866361, -0.61851865,  0.7857701 ,\n",
              "                 0.25774407,  0.9662133 ],\n",
              "               [ 0.49871314, -0.86676705, -0.5813935 ,  0.81362253,\n",
              "                 0.2598251 ,  0.96565574],\n",
              "               [-0.4599035 , -0.8879689 , -0.5430155 ,  0.83972263,\n",
              "                 0.26190498,  0.96509373],\n",
              "               [-0.995687  , -0.09277621, -0.5034682 ,  0.8640137 ,\n",
              "                 0.26398358,  0.9645272 ],\n",
              "               [-0.6160404 ,  0.78771454, -0.46283653,  0.8864436 ,\n",
              "                 0.26606098,  0.96395624],\n",
              "               [ 0.32999083,  0.94398415, -0.42120782,  0.9069641 ,\n",
              "                 0.26813713,  0.9633808 ],\n",
              "               [ 0.9726301 ,  0.23235911, -0.37867135,  0.9255312 ,\n",
              "                 0.27021205,  0.96280086]]], dtype=float32)))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test MultiHeadSelfAttention"
      ],
      "metadata": {
        "id": "O49z4SUrwlUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mhsa = MultiHeadSelfAttention.create(key, dim=4, heads=2, causal=True)"
      ],
      "metadata": {
        "id": "1HEVlqWMwm0m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mhsa"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPAb9RX9wruw",
        "outputId": "89513d81-6c5a-47e7-d176-4ca49a26e372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultiHeadSelfAttention(to_q=Linear(weight=DeviceArray([[-0.00089805, -0.01187019, -0.02608371, -0.00651822],\n",
              "             [ 0.02117782,  0.01724769,  0.03117264, -0.01532539],\n",
              "             [ 0.01588214,  0.00171302, -0.03031087,  0.01194714],\n",
              "             [-0.00190441, -0.00632263, -0.00731096,  0.01891298]],            dtype=float32), bias=DeviceArray([0., 0., 0., 0.], dtype=float32)), to_k=Linear(weight=DeviceArray([[ 0.00914821,  0.01309405, -0.00554321, -0.01999797],\n",
              "             [-0.01012122,  0.02966917, -0.02834937, -0.02397629],\n",
              "             [ 0.00108852,  0.02056246,  0.00646167, -0.01054484],\n",
              "             [-0.02017942, -0.00302269,  0.01521268,  0.00180503]],            dtype=float32), bias=DeviceArray([0., 0., 0., 0.], dtype=float32)), to_v=Linear(weight=DeviceArray([[ 0.01202872,  0.01929402, -0.02928475,  0.00571518],\n",
              "             [ 0.02516833, -0.0003231 , -0.01465918,  0.03156444],\n",
              "             [ 0.00365178, -0.00108856,  0.0004419 , -0.02173013],\n",
              "             [ 0.0332577 ,  0.02641883, -0.03112677,  0.01259286]],            dtype=float32), bias=DeviceArray([0., 0., 0., 0.], dtype=float32)), to_out=Linear(weight=DeviceArray([[-0.0093767 , -0.01474209,  0.04316621,  0.00152129],\n",
              "             [ 0.01598843,  0.01710789, -0.02504996,  0.02864788],\n",
              "             [-0.03414704,  0.01624052,  0.00252561, -0.03355112],\n",
              "             [ 0.01656959, -0.0091875 ,  0.01392681,  0.0083006 ]],            dtype=float32), bias=DeviceArray([0., 0., 0., 0.], dtype=float32)), heads=2, scale=0.5, causal=True)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = jax.random.normal(key, (2, 5, 4))\n",
        "mask = jnp.ones((2, 5), dtype=jnp.int32)\n",
        "x.shape, x.mean(), x.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdI8W6CXwxN0",
        "outputId": "038b8a9f-896b-4cdd-b699-1b1fd8430b25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2, 5, 4),\n",
              " DeviceArray(-0.02352496, dtype=float32),\n",
              " DeviceArray(0.88507974, dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = mhsa(x)\n",
        "out.shape, out.mean(), out.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYhT1zGKw36n",
        "outputId": "2aac060a-0401-4e2d-ebb6-28ea35fed161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2, 5, 4),\n",
              " DeviceArray(-0.00019259, dtype=float32),\n",
              " DeviceArray(0.00080619, dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S16WEtdlxJmN",
        "outputId": "e0b2879c-2855-42f2-fa38-bd2fa05848ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[[ 3.5223365e-04, -1.2261616e-03,  2.6063018e-03,\n",
              "                1.1798181e-04],\n",
              "              [ 4.3814257e-04, -4.4755638e-04,  8.4447488e-04,\n",
              "                6.5770186e-04],\n",
              "              [-6.5640733e-04, -1.1401251e-05,  3.1622685e-04,\n",
              "               -7.8875409e-04],\n",
              "              [-5.0159823e-04,  2.1421816e-04, -1.5031733e-04,\n",
              "               -4.5840588e-04],\n",
              "              [-5.8657490e-04,  2.7089007e-04, -2.0534918e-04,\n",
              "               -5.0072849e-04]],\n",
              "\n",
              "             [[-1.4229901e-03,  1.4643967e-03, -2.2975169e-03,\n",
              "               -1.6099121e-03],\n",
              "              [-6.9512241e-04,  4.2846799e-04, -5.1409192e-04,\n",
              "               -5.7392474e-04],\n",
              "              [-5.9274631e-04,  9.6970703e-05,  6.2740408e-05,\n",
              "               -6.1600597e-04],\n",
              "              [-5.1280484e-04,  3.0975789e-04, -3.7076324e-04,\n",
              "               -5.4342020e-04],\n",
              "              [-2.6065041e-04,  2.2208970e-04, -3.2328092e-04,\n",
              "               -2.3981044e-04]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def mhsa_jitted(x):\n",
        "  return mhsa(x)\n",
        "\n",
        "mhsa_jitted(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vjms8-H0xWJR",
        "outputId": "7190bb17-16e6-49e2-8ed1-650eb8b01b54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[[ 3.5223365e-04, -1.2261616e-03,  2.6063018e-03,\n",
              "                1.1798181e-04],\n",
              "              [ 4.3814257e-04, -4.4755638e-04,  8.4447488e-04,\n",
              "                6.5770186e-04],\n",
              "              [-6.5640733e-04, -1.1401251e-05,  3.1622685e-04,\n",
              "               -7.8875409e-04],\n",
              "              [-5.0159823e-04,  2.1421816e-04, -1.5031733e-04,\n",
              "               -4.5840588e-04],\n",
              "              [-5.8657490e-04,  2.7089007e-04, -2.0534918e-04,\n",
              "               -5.0072849e-04]],\n",
              "\n",
              "             [[-1.4229901e-03,  1.4643967e-03, -2.2975169e-03,\n",
              "               -1.6099121e-03],\n",
              "              [-6.9512241e-04,  4.2846799e-04, -5.1409192e-04,\n",
              "               -5.7392474e-04],\n",
              "              [-5.9274631e-04,  9.6970703e-05,  6.2740408e-05,\n",
              "               -6.1600597e-04],\n",
              "              [-5.1280484e-04,  3.0975789e-04, -3.7076324e-04,\n",
              "               -5.4342020e-04],\n",
              "              [-2.6065041e-04,  2.2208970e-04, -3.2328092e-04,\n",
              "               -2.3981044e-04]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x2 = jax.random.normal(key, (2, 6, 4))\n",
        "mhsa_jitted(x2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bz5Td3GnxmMw",
        "outputId": "3a9175a3-3a76-477d-ed91-2563f5379524"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[[ 9.2355162e-04, -1.0871887e-04, -7.6125190e-04,\n",
              "                8.7211886e-04],\n",
              "              [-3.3225864e-05,  1.4514849e-04, -3.4664199e-04,\n",
              "                4.0661893e-04],\n",
              "              [-1.5203953e-03,  6.6145509e-04, -7.1850792e-04,\n",
              "               -1.7885081e-03],\n",
              "              [-1.0284185e-03,  5.4180622e-04, -7.4449927e-04,\n",
              "               -1.3139276e-03],\n",
              "              [-6.1343610e-04,  1.6504666e-04, -1.3730675e-04,\n",
              "               -8.9899823e-04],\n",
              "              [-1.3208017e-04, -3.8671307e-05,  8.7017193e-05,\n",
              "               -2.6368489e-04]],\n",
              "\n",
              "             [[ 3.9270520e-03, -1.8672496e-03,  1.8774718e-03,\n",
              "                4.5844503e-03],\n",
              "              [ 1.5179217e-03, -3.8094819e-04, -3.2663345e-05,\n",
              "                1.7614253e-03],\n",
              "              [ 2.3819357e-03, -1.1696666e-03,  1.2358502e-03,\n",
              "                2.6842095e-03],\n",
              "              [ 1.2893528e-03, -3.9525330e-04,  1.6123429e-04,\n",
              "                1.4953753e-03],\n",
              "              [ 6.0330518e-04, -1.0314491e-04, -1.1182949e-04,\n",
              "                7.4336969e-04],\n",
              "              [ 5.6129694e-04, -1.4650822e-04,  1.0151416e-05,\n",
              "                6.5750955e-04]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_mhsa(mhsa, x):\n",
        "  out = mhsa(x)\n",
        "  return out[:, 1:, :].mean()\n",
        "\n",
        "jax.value_and_grad(loss_mhsa)(mhsa, x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jz-Qcpqbxqre",
        "outputId": "ef656734-b937-4214-fd6c-2d46d4bd3627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(DeviceArray(-0.00017775, dtype=float32),\n",
              " MultiHeadSelfAttention(to_q=Linear(weight=DeviceArray([[ 6.46040462e-07,  6.88114596e-07, -3.13149940e-07,\n",
              "               -1.47636456e-07],\n",
              "              [ 2.74369086e-07,  2.08567872e-06, -1.17850504e-07,\n",
              "               -8.28302291e-07],\n",
              "              [-9.40899554e-07,  1.79679773e-08, -5.03086085e-07,\n",
              "               -6.06317371e-07],\n",
              "              [ 1.98949238e-07, -2.33972969e-07, -6.26538167e-07,\n",
              "               -4.72522515e-07]], dtype=float32), bias=DeviceArray([-1.5929963e-06, -2.9211435e-07, -2.1658570e-06,\n",
              "              -2.4130231e-06], dtype=float32)), to_k=Linear(weight=DeviceArray([[-5.2903907e-08, -1.5833085e-07,  1.1134828e-06,\n",
              "               -6.1250307e-07],\n",
              "              [ 1.0833571e-06,  8.3119915e-07, -1.6174517e-06,\n",
              "                9.9819181e-07],\n",
              "              [ 6.1145408e-07,  2.9176141e-07,  1.2890612e-06,\n",
              "               -6.8019631e-07],\n",
              "              [-3.6285272e-08, -1.8763001e-07, -1.5651433e-06,\n",
              "                1.0016272e-06]], dtype=float32), bias=DeviceArray([-7.4247097e-10, -6.1396577e-10, -6.1322680e-10,\n",
              "               1.5415935e-09], dtype=float32)), to_v=Linear(weight=DeviceArray([[-0.00148325, -0.00264941,  0.00351973, -0.00213104],\n",
              "              [-0.00025637, -0.00046486,  0.00061244, -0.00037205],\n",
              "              [ 0.00175339,  0.00312559, -0.0041586 ,  0.00251712],\n",
              "              [ 0.00050729,  0.0009148 , -0.00119874,  0.00072721]],            dtype=float32), bias=DeviceArray([ 0.00513071,  0.00916198, -0.01221597,  0.00739066], dtype=float32)), to_out=Linear(weight=DeviceArray([[-5.9723854e-05, -5.9723854e-05, -5.9723854e-05,\n",
              "               -5.9723854e-05],\n",
              "              [-8.2677603e-04, -8.2677603e-04, -8.2677603e-04,\n",
              "               -8.2677603e-04],\n",
              "              [ 1.5668869e-03,  1.5668869e-03,  1.5668869e-03,\n",
              "                1.5668869e-03],\n",
              "              [-2.3508072e-03, -2.3508072e-03, -2.3508072e-03,\n",
              "               -2.3508072e-03]], dtype=float32), bias=DeviceArray([0.25, 0.25, 0.25, 0.25], dtype=float32)), heads=2, scale=0.5, causal=True))"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test TransformerBlock"
      ],
      "metadata": {
        "id": "gkbRwZ4gx4BN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = TransformerBlock.create(key, dim=4, heads=2)\n",
        "\n",
        "t_out = t(x, mask)\n",
        "t_out.shape, t_out.mean(), t_out.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBgIs3yNx5QR",
        "outputId": "b8b3e4c5-038f-4981-aa70-06d4184d2911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2, 5, 4),\n",
              " DeviceArray(-0.02326439, dtype=float32),\n",
              " DeviceArray(0.88490736, dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_transformer_block(t, x, mask):\n",
        "  return t(x, mask).mean()\n",
        "\n",
        "jax.value_and_grad(loss_transformer_block)(t, x, mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UsPJ2-3yY0g",
        "outputId": "e50b3b8e-4af9-4c47-b1a2-9d4c4ae8e6a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(DeviceArray(-0.02326439, dtype=float32),\n",
              " TransformerBlock(mhsa=MultiHeadSelfAttention(to_q=Linear(weight=DeviceArray([[-5.4389147e-08,  1.7117921e-07, -8.4261410e-07,\n",
              "               -1.5639525e-06],\n",
              "              [-1.0106828e-07,  2.1043543e-07, -1.4797588e-06,\n",
              "               -3.3825381e-06],\n",
              "              [-1.4524369e-07,  1.4143134e-07,  4.7742651e-07,\n",
              "                2.2085278e-06],\n",
              "              [ 1.6177825e-07, -2.3961655e-07, -1.0833901e-06,\n",
              "                1.7149414e-06]], dtype=float32), bias=DeviceArray([ 5.2197697e-07, -8.2022586e-07, -8.9804644e-07,\n",
              "               8.9167024e-06], dtype=float32)), to_k=Linear(weight=DeviceArray([[-1.2429228e-07,  1.5513075e-07,  2.0687435e-07,\n",
              "                9.2135679e-08],\n",
              "              [ 2.3636471e-07,  4.4608021e-07,  1.3423653e-06,\n",
              "               -7.8048879e-07],\n",
              "              [-4.8289792e-08,  2.3543703e-07,  1.3293975e-06,\n",
              "               -2.2027643e-07],\n",
              "              [-5.4716995e-08, -4.0551726e-07, -4.7919423e-07,\n",
              "                6.7847634e-07]], dtype=float32), bias=DeviceArray([ 6.8098416e-11,  9.9760200e-10,  1.4160833e-09,\n",
              "              -1.3451427e-09], dtype=float32)), to_v=Linear(weight=DeviceArray([[ 2.0798761e-03, -2.2787310e-05, -6.3623413e-03,\n",
              "               -2.4983808e-03],\n",
              "              [ 3.3953739e-04, -3.3973047e-06, -1.0272097e-03,\n",
              "               -3.9314758e-04],\n",
              "              [-1.2442190e-03,  1.3952638e-05,  3.8150400e-03,\n",
              "                1.5131645e-03],\n",
              "              [-8.3067454e-04,  9.1646652e-06,  2.5398824e-03,\n",
              "                9.9415425e-04]], dtype=float32), bias=DeviceArray([-5.2642822e-03,  5.7875586e-05,  1.6134851e-02,\n",
              "               6.3501410e-03], dtype=float32)), to_out=Linear(weight=DeviceArray([[-0.00657074, -0.00657074, -0.00655101, -0.00657074],\n",
              "              [-0.00613162, -0.00613162, -0.00611435, -0.00613162],\n",
              "              [ 0.00243004,  0.00243004,  0.0024238 ,  0.00243004],\n",
              "              [ 0.00112806,  0.00112806,  0.00112484,  0.00112806]],            dtype=float32), bias=DeviceArray([0.25012928, 0.24985331, 0.2496286 , 0.25038883], dtype=float32)), heads=2, scale=0.5, causal=True), mlp=MLP(layers=[Linear(weight=DeviceArray([[-0.00033927,  0.00068672,  0.00117885, -0.00170296,\n",
              "                0.00077455,  0.00190835,  0.00123465,  0.00068668,\n",
              "                0.00241497, -0.00302754, -0.00086232, -0.00062078,\n",
              "               -0.00106724,  0.00064154,  0.00080221,  0.00197739],\n",
              "              [-0.00033982,  0.00049691,  0.00095439, -0.00132398,\n",
              "                0.00050452,  0.00221347,  0.00131232,  0.00027207,\n",
              "                0.00202934, -0.00350082, -0.00087045, -0.00076879,\n",
              "               -0.00113599,  0.00082138,  0.00061174,  0.00135571],\n",
              "              [ 0.00047918, -0.00090712, -0.00183201,  0.00190366,\n",
              "               -0.0011182 , -0.0021593 , -0.00132321, -0.00092369,\n",
              "               -0.00292406,  0.00282751,  0.00093371,  0.0007181 ,\n",
              "                0.00131247, -0.00071554, -0.00104638, -0.00249122],\n",
              "              [ 0.00026834, -0.00038755, -0.00069355,  0.00121816,\n",
              "               -0.00048593, -0.00167355, -0.00085572, -0.00031838,\n",
              "               -0.00166063,  0.00238592,  0.00069598,  0.00052563,\n",
              "                0.00078978, -0.00051668, -0.00069731, -0.00125668]],            dtype=float32), bias=DeviceArray([ 0.001426  , -0.00278033, -0.00527889,  0.00658332,\n",
              "              -0.00317246, -0.00783277, -0.00505898, -0.00268912,\n",
              "              -0.00970526,  0.01206399,  0.00341132,  0.00257923,\n",
              "               0.00442422, -0.00269695, -0.00312585, -0.00758315],            dtype=float32)), Linear(weight=DeviceArray([[ 0.00240301,  0.00240301,  0.00240301,  0.00240301],\n",
              "              [-0.00037077, -0.00037077, -0.00037077, -0.00037077],\n",
              "              [-0.00122571, -0.00122571, -0.00122571, -0.00122571],\n",
              "              [-0.00050342, -0.00050342, -0.00050342, -0.00050342],\n",
              "              [ 0.00042513,  0.00042513,  0.00042513,  0.00042513],\n",
              "              [ 0.00098935,  0.00098935,  0.00098935,  0.00098935],\n",
              "              [-0.00124595, -0.00124595, -0.00124595, -0.00124595],\n",
              "              [-0.0016129 , -0.0016129 , -0.0016129 , -0.0016129 ],\n",
              "              [-0.00042363, -0.00042363, -0.00042363, -0.00042363],\n",
              "              [-0.00076521, -0.00076521, -0.00076521, -0.00076521],\n",
              "              [ 0.00043683,  0.00043683,  0.00043683,  0.00043683],\n",
              "              [ 0.00147129,  0.00147129,  0.00147129,  0.00147129],\n",
              "              [ 0.00071567,  0.00071567,  0.00071567,  0.00071567],\n",
              "              [ 0.00063839,  0.00063839,  0.00063839,  0.00063839],\n",
              "              [ 0.00283251,  0.00283251,  0.00283251,  0.00283251],\n",
              "              [ 0.00133568,  0.00133568,  0.00133568,  0.00133568]],            dtype=float32), bias=DeviceArray([0.25, 0.25, 0.25, 0.25], dtype=float32))]), ln1=LayerNorm(gamma=DeviceArray([0.00032247], dtype=float32), beta=DeviceArray([-0.0003732], dtype=float32)), ln2=LayerNorm(gamma=DeviceArray([-8.791632e-05], dtype=float32), beta=DeviceArray([-0.00119084], dtype=float32))))"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test DecoderLM"
      ],
      "metadata": {
        "id": "pf_53VvwyiSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d = DecoderLM.create(key, vocab_size=3, num_layers=2, dim=4, heads=2, max_seq_len=3)"
      ],
      "metadata": {
        "id": "ZkaCsgcCyjSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(jax.tree_map(lambda p: jnp.shape(p), d))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnMm6OkIynuG",
        "outputId": "7b82ca6d-d09e-4810-84d1-b8da3fe328de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecoderLM(embeddings=Embeddings(weight=(3, 4)),\n",
            "          pos_embs=SinusoidalPositionEmbeddings(weight=DeviceArray([[[ 0.        ,  1.        ,  0.        ,  1.        ],\n",
            "              [ 0.84147096,  0.5403023 ,  0.00999987,  0.99995   ],\n",
            "              [ 0.9092974 , -0.41614684,  0.01999873,  0.9998    ]]],            dtype=float32)),\n",
            "          layers=[TransformerBlock(mhsa=MultiHeadSelfAttention(to_q=Linear(weight=(4,\n",
            "                                                                                   4),\n",
            "                                                                           bias=(4,)),\n",
            "                                                               to_k=Linear(weight=(4,\n",
            "                                                                                   4),\n",
            "                                                                           bias=(4,)),\n",
            "                                                               to_v=Linear(weight=(4,\n",
            "                                                                                   4),\n",
            "                                                                           bias=(4,)),\n",
            "                                                               to_out=Linear(weight=(4,\n",
            "                                                                                     4),\n",
            "                                                                             bias=(4,)),\n",
            "                                                               heads=2,\n",
            "                                                               scale=0.5,\n",
            "                                                               causal=True),\n",
            "                                   mlp=MLP(layers=[Linear(weight=(4, 16),\n",
            "                                                          bias=(16,)),\n",
            "                                                   Linear(weight=(16, 4),\n",
            "                                                          bias=(4,))]),\n",
            "                                   ln1=LayerNorm(gamma=(1,), beta=(1,)),\n",
            "                                   ln2=LayerNorm(gamma=(1,), beta=(1,))),\n",
            "                  TransformerBlock(mhsa=MultiHeadSelfAttention(to_q=Linear(weight=(4,\n",
            "                                                                                   4),\n",
            "                                                                           bias=(4,)),\n",
            "                                                               to_k=Linear(weight=(4,\n",
            "                                                                                   4),\n",
            "                                                                           bias=(4,)),\n",
            "                                                               to_v=Linear(weight=(4,\n",
            "                                                                                   4),\n",
            "                                                                           bias=(4,)),\n",
            "                                                               to_out=Linear(weight=(4,\n",
            "                                                                                     4),\n",
            "                                                                             bias=(4,)),\n",
            "                                                               heads=2,\n",
            "                                                               scale=0.5,\n",
            "                                                               causal=True),\n",
            "                                   mlp=MLP(layers=[Linear(weight=(4, 16),\n",
            "                                                          bias=(16,)),\n",
            "                                                   Linear(weight=(16, 4),\n",
            "                                                          bias=(4,))]),\n",
            "                                   ln1=LayerNorm(gamma=(1,), beta=(1,)),\n",
            "                                   ln2=LayerNorm(gamma=(1,), beta=(1,)))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(jax.tree_map(lambda p: jnp.std(p), d))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1caicA_Jyx1D",
        "outputId": "be52aee1-76bd-47a4-9741-3c55d0303eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecoderLM(embeddings=Embeddings(weight=DeviceArray(0.01798398, dtype=float32)),\n",
            "          pos_embs=SinusoidalPositionEmbeddings(weight=DeviceArray([[[ 0.        ,  1.        ,  0.        ,  1.        ],\n",
            "              [ 0.84147096,  0.5403023 ,  0.00999987,  0.99995   ],\n",
            "              [ 0.9092974 , -0.41614684,  0.01999873,  0.9998    ]]],            dtype=float32)),\n",
            "          layers=[TransformerBlock(mhsa=MultiHeadSelfAttention(to_q=Linear(weight=DeviceArray(0.01451548, dtype=float32),\n",
            "                                                                           bias=DeviceArray(0., dtype=float32)),\n",
            "                                                               to_k=Linear(weight=DeviceArray(0.02478699, dtype=float32),\n",
            "                                                                           bias=DeviceArray(0., dtype=float32)),\n",
            "                                                               to_v=Linear(weight=DeviceArray(0.02526536, dtype=float32),\n",
            "                                                                           bias=DeviceArray(0., dtype=float32)),\n",
            "                                                               to_out=Linear(weight=DeviceArray(0.00745102, dtype=float32),\n",
            "                                                                             bias=DeviceArray(0., dtype=float32)),\n",
            "                                                               heads=2,\n",
            "                                                               scale=0.5,\n",
            "                                                               causal=True),\n",
            "                                   mlp=MLP(layers=[Linear(weight=DeviceArray(0.01761369, dtype=float32),\n",
            "                                                          bias=DeviceArray(0., dtype=float32)),\n",
            "                                                   Linear(weight=DeviceArray(0.01879291, dtype=float32),\n",
            "                                                          bias=DeviceArray(0., dtype=float32))]),\n",
            "                                   ln1=LayerNorm(gamma=DeviceArray(0., dtype=float32),\n",
            "                                                 beta=DeviceArray(0., dtype=float32)),\n",
            "                                   ln2=LayerNorm(gamma=DeviceArray(0., dtype=float32),\n",
            "                                                 beta=DeviceArray(0., dtype=float32))),\n",
            "                  TransformerBlock(mhsa=MultiHeadSelfAttention(to_q=Linear(weight=DeviceArray(0.01976321, dtype=float32),\n",
            "                                                                           bias=DeviceArray(0., dtype=float32)),\n",
            "                                                               to_k=Linear(weight=DeviceArray(0.01987706, dtype=float32),\n",
            "                                                                           bias=DeviceArray(0., dtype=float32)),\n",
            "                                                               to_v=Linear(weight=DeviceArray(0.01546579, dtype=float32),\n",
            "                                                                           bias=DeviceArray(0., dtype=float32)),\n",
            "                                                               to_out=Linear(weight=DeviceArray(0.00861966, dtype=float32),\n",
            "                                                                             bias=DeviceArray(0., dtype=float32)),\n",
            "                                                               heads=2,\n",
            "                                                               scale=0.5,\n",
            "                                                               causal=True),\n",
            "                                   mlp=MLP(layers=[Linear(weight=DeviceArray(0.01862142, dtype=float32),\n",
            "                                                          bias=DeviceArray(0., dtype=float32)),\n",
            "                                                   Linear(weight=DeviceArray(0.0195837, dtype=float32),\n",
            "                                                          bias=DeviceArray(0., dtype=float32))]),\n",
            "                                   ln1=LayerNorm(gamma=DeviceArray(0., dtype=float32),\n",
            "                                                 beta=DeviceArray(0., dtype=float32)),\n",
            "                                   ln2=LayerNorm(gamma=DeviceArray(0., dtype=float32),\n",
            "                                                 beta=DeviceArray(0., dtype=float32)))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_mask = jnp.ones_like(ids, dtype=jnp.int32)\n",
        "d_out = d(ids, ids_mask)\n",
        "d_out.shape, d_out.mean(), d_out.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBSxylqPy8ae",
        "outputId": "88881280-a077-48f3-c7b8-a096560dfeb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2, 3, 3),\n",
              " DeviceArray(-1.0991278, dtype=float32),\n",
              " DeviceArray(0.03028868, dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jnp.exp(d_out)  # check that exponentiating logits yields probs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nke6yZQnzBuA",
        "outputId": "ca726faf-1969-4cad-ea6b-7eb0238e4af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[[0.346286  , 0.32860494, 0.32505128],\n",
              "              [0.34975418, 0.32043424, 0.32974482],\n",
              "              [0.34419867, 0.3234423 , 0.3323133 ]],\n",
              "\n",
              "             [[0.3465706 , 0.3280305 , 0.32534248],\n",
              "              [0.34975418, 0.32043424, 0.32974482],\n",
              "              [0.34419867, 0.3234423 , 0.3323133 ]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_decoder_lm(d, ids, mask):\n",
        "  return 100 * d(ids, mask).mean()\n",
        "\n",
        "jax.value_and_grad(loss_decoder_lm)(d, ids, ids_mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fs3a4up_zNPB",
        "outputId": "318a4c26-9c18-4f2b-d6d2-a3e35d927094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(DeviceArray(-109.91278, dtype=float32),\n",
              " DecoderLM(embeddings=Embeddings(weight=DeviceArray([[-0.8196529 , -0.5671234 , -0.03178539, -1.3359756 ],\n",
              "              [ 0.67937213,  0.24673419,  0.02402913,  0.9102438 ],\n",
              "              [ 0.1238312 ,  0.30758926,  0.00296418,  0.41365167]],            dtype=float32)), pos_embs=SinusoidalPositionEmbeddings(weight=DeviceArray([[[ 0.        ,  1.        ,  0.        ,  1.        ],\n",
              "               [ 0.84147096,  0.5403023 ,  0.00999987,  0.99995   ],\n",
              "               [ 0.9092974 , -0.41614684,  0.01999873,  0.9998    ]]],            dtype=float32)), layers=[TransformerBlock(mhsa=MultiHeadSelfAttention(to_q=Linear(weight=DeviceArray([[ 7.5875846e-08,  1.5500518e-07, -4.7552930e-08,\n",
              "               -9.7359589e-08],\n",
              "              [-1.4707106e-07, -2.3804250e-07,  6.5336053e-08,\n",
              "                9.5900759e-08],\n",
              "              [-7.9839424e-08, -1.6917284e-07,  5.2647238e-08,\n",
              "                1.1143129e-07],\n",
              "              [ 8.5168892e-08,  1.7968568e-07, -5.5826376e-08,\n",
              "               -1.1774500e-07]], dtype=float32), bias=DeviceArray([ 8.7692570e-08,  1.8555647e-07, -5.7583378e-08,\n",
              "              -1.2124679e-07], dtype=float32)), to_k=Linear(weight=DeviceArray([[ 7.2801754e-08, -4.5872575e-08,  5.1483994e-08,\n",
              "               -3.6881090e-08],\n",
              "              [-1.2346911e-07,  6.8486578e-08, -4.6920036e-08,\n",
              "                1.9378962e-08],\n",
              "              [ 2.2424729e-09, -1.2229471e-09,  1.2458941e-09,\n",
              "               -7.7871309e-10],\n",
              "              [-5.6803628e-10,  2.5562485e-10, -4.6213700e-10,\n",
              "                3.5914471e-10]], dtype=float32), bias=DeviceArray([ 4.1382009e-11, -2.1827873e-11,  0.0000000e+00,\n",
              "               0.0000000e+00], dtype=float32)), to_v=Linear(weight=DeviceArray([[-2.1677464e-05,  3.6591664e-06, -1.9166991e-04,\n",
              "               -3.1832838e-05],\n",
              "              [ 1.0109320e-04,  3.0488707e-05,  2.5654305e-04,\n",
              "                2.8481591e-05],\n",
              "              [-3.9873086e-04, -1.6314257e-04, -4.3599866e-04,\n",
              "               -4.0153973e-06],\n",
              "              [ 4.1407906e-04,  1.6961526e-04,  4.5019388e-04,\n",
              "                3.6826823e-06]], dtype=float32), bias=DeviceArray([4.2347424e-04, 1.7373869e-04, 4.5871735e-04, 3.4570694e-06],            dtype=float32)), to_out=Linear(weight=DeviceArray([[-0.0015122 , -0.00092549, -0.00043451, -0.00077554],\n",
              "              [ 0.00144977,  0.00085535,  0.00041988,  0.00068982],\n",
              "              [ 0.00086831,  0.00052848,  0.00024979,  0.00044102],\n",
              "              [ 0.00112731,  0.00095297,  0.00029656,  0.00102498]],            dtype=float32), bias=DeviceArray([-0.05486227, -0.03904741, -0.01522348, -0.03745298], dtype=float32)), heads=2, scale=0.5, causal=True), mlp=MLP(layers=[Linear(weight=DeviceArray([[-1.02072954e-04, -1.47540122e-04,  1.95583329e-04,\n",
              "                3.39884311e-04, -4.01370227e-04,  2.64290720e-05,\n",
              "               -2.34590843e-05, -5.28123230e-04, -4.51289117e-04,\n",
              "               -3.81078571e-05,  7.58163631e-04, -1.97838293e-04,\n",
              "                1.42561737e-04,  1.95674598e-04, -3.66568565e-04,\n",
              "               -3.09910625e-04],\n",
              "              [ 6.02146611e-05,  1.32489949e-04, -1.61243603e-04,\n",
              "               -2.70094723e-04,  3.10719013e-04,  1.84401870e-07,\n",
              "                2.71294266e-06,  4.63325530e-04,  4.07632440e-04,\n",
              "               -8.10064375e-06, -6.38745725e-04,  2.03764299e-04,\n",
              "               -1.43397076e-04, -2.04006443e-04,  3.02307308e-04,\n",
              "                2.13567168e-04],\n",
              "              [ 4.60678712e-04,  3.94383445e-04, -4.32295725e-04,\n",
              "               -1.05926767e-03,  1.28172711e-03, -2.81360000e-04,\n",
              "                2.16143671e-04,  1.52093545e-03,  8.45849514e-04,\n",
              "                4.86935489e-04, -2.12714076e-03,  2.80412147e-04,\n",
              "               -1.82732125e-04, -2.47546937e-04,  1.21969357e-03,\n",
              "                1.05130672e-03],\n",
              "              [-4.81784344e-04, -4.13764268e-04,  4.53958288e-04,\n",
              "                1.10999867e-03, -1.34286284e-03,  2.93597579e-04,\n",
              "               -2.25601252e-04, -1.59486756e-03, -8.89718533e-04,\n",
              "               -5.07984310e-04,  2.23060697e-03, -2.96042534e-04,\n",
              "                1.93128479e-04,  2.61749607e-04, -1.27782673e-03,\n",
              "               -1.10087916e-03]], dtype=float32), bias=DeviceArray([-0.00049313, -0.0004236 ,  0.00046533,  0.00113801,\n",
              "              -0.00137623,  0.00030044, -0.00023067, -0.00163251,\n",
              "              -0.00091215, -0.00051899,  0.00228741, -0.00030383,\n",
              "               0.00019867,  0.00026886, -0.00130896, -0.00112818],            dtype=float32)), Linear(weight=DeviceArray([[-9.84713435e-04, -7.48425722e-04, -2.67369673e-04,\n",
              "               -7.48753548e-04],\n",
              "              [-3.63732455e-04, -2.05780379e-04, -1.06314255e-04,\n",
              "               -1.55805610e-04],\n",
              "              [ 8.52689671e-04,  5.15729655e-04,  2.45668401e-04,\n",
              "                4.23898804e-04],\n",
              "              [ 3.82838771e-04,  3.73791903e-04,  9.50954854e-05,\n",
              "                4.30214219e-04],\n",
              "              [ 3.37905250e-04,  2.25694384e-04,  9.50751128e-05,\n",
              "                2.04242766e-04],\n",
              "              [ 7.56182708e-05,  6.68521971e-05,  1.95297180e-05,\n",
              "                7.39227980e-05],\n",
              "              [ 1.36963092e-04,  1.10342167e-04,  3.65206506e-05,\n",
              "                1.14531722e-04],\n",
              "              [-1.50301866e-03, -9.66273248e-04, -4.26920597e-04,\n",
              "               -8.43703747e-04],\n",
              "              [-7.80256232e-06, -1.12287002e-04,  9.25062341e-06,\n",
              "               -1.84999750e-04],\n",
              "              [-3.05333757e-04, -1.82537362e-04, -8.81980814e-05,\n",
              "               -1.48113584e-04],\n",
              "              [-6.05065376e-04, -3.33728269e-04, -1.77771319e-04,\n",
              "               -2.47092918e-04],\n",
              "              [-1.87840313e-04, -7.70762563e-06, -6.54384494e-05,\n",
              "                8.58940184e-05],\n",
              "              [-7.13602640e-04, -4.52578068e-04, -2.03354983e-04,\n",
              "               -3.90602276e-04],\n",
              "              [-3.27685848e-04, -1.53683126e-04, -9.91672277e-05,\n",
              "               -8.68132338e-05],\n",
              "              [-2.73192767e-04, -1.03149563e-04, -8.53457022e-05,\n",
              "               -3.04917339e-05],\n",
              "              [-1.72895938e-03, -1.29389018e-03, -4.71604988e-04,\n",
              "               -1.28103048e-03]], dtype=float32), bias=DeviceArray([-0.05506615, -0.03910416, -0.01519905, -0.03721678], dtype=float32))]), ln1=LayerNorm(gamma=DeviceArray([1.5493649e-06], dtype=float32), beta=DeviceArray([-1.554623e-05], dtype=float32)), ln2=LayerNorm(gamma=DeviceArray([-0.00015508], dtype=float32), beta=DeviceArray([-6.63097e-05], dtype=float32))), TransformerBlock(mhsa=MultiHeadSelfAttention(to_q=Linear(weight=DeviceArray([[ 4.0721261e-08, -7.9596703e-08,  1.2278373e-10,\n",
              "               -1.3486292e-09],\n",
              "              [-4.9365667e-08,  1.1042306e-07, -2.5747293e-10,\n",
              "                2.7513312e-09],\n",
              "              [-4.5881734e-08,  8.8321030e-08, -1.2760737e-10,\n",
              "                1.4076385e-09],\n",
              "              [ 4.8743004e-08, -9.3990366e-08,  1.3693086e-10,\n",
              "               -1.5110468e-09]], dtype=float32), bias=DeviceArray([ 5.0022820e-08, -9.6453164e-08,  1.4072832e-10,\n",
              "              -1.5534170e-09], dtype=float32)), to_k=Linear(weight=DeviceArray([[ 4.2925592e-09,  8.1849919e-08, -7.6519768e-10,\n",
              "               -7.0136537e-09],\n",
              "              [-3.1760941e-09, -1.1212601e-07,  1.6214168e-09,\n",
              "                1.6003550e-08],\n",
              "              [ 9.7003294e-11,  2.2770337e-09, -2.9878322e-11,\n",
              "               -2.6952307e-10],\n",
              "              [-3.3054448e-11, -4.9413984e-10,  6.7821304e-12,\n",
              "                4.6696869e-11]], dtype=float32), bias=DeviceArray([-2.7977620e-13, -2.1429969e-11,  1.4139800e-12,\n",
              "               1.4239276e-11], dtype=float32)), to_v=Linear(weight=DeviceArray([[ 1.8463237e-05,  1.2732911e-04,  2.2553280e-04,\n",
              "                1.7806608e-04],\n",
              "              [ 5.7960860e-06, -1.4651491e-04, -3.6550127e-04,\n",
              "               -2.5787018e-04],\n",
              "              [-1.0639592e-04,  1.7765290e-04,  8.2874671e-04,\n",
              "                5.0428230e-04],\n",
              "              [ 1.1105114e-04, -1.8274810e-04, -8.5874274e-04,\n",
              "               -5.2183773e-04]], dtype=float32), bias=DeviceArray([ 0.0001137 , -0.00018567, -0.000875  , -0.00053215], dtype=float32)), to_out=Linear(weight=DeviceArray([[-4.9258769e-04, -4.8491359e-04, -1.2091361e-04,\n",
              "               -5.5988133e-04],\n",
              "              [-2.3434982e-03, -1.6820207e-03, -6.4423867e-04,\n",
              "               -1.6130134e-03],\n",
              "              [ 2.6230700e-04,  1.9707903e-04,  7.1093673e-05,\n",
              "                1.9557681e-04],\n",
              "              [-2.6536454e-04, -2.0679552e-04, -7.1063871e-05,\n",
              "               -2.1051150e-04]], dtype=float32), bias=DeviceArray([-0.05508746, -0.03912868, -0.01517744, -0.03719256], dtype=float32)), heads=2, scale=0.5, causal=True), mlp=MLP(layers=[Linear(weight=DeviceArray([[-2.6371703e-04, -8.5458159e-06, -2.2403151e-04,\n",
              "                4.2419508e-04,  1.6272068e-05, -3.0235201e-04,\n",
              "               -4.1574705e-05,  1.3485365e-04, -2.5355071e-04,\n",
              "                2.2444129e-04,  3.2068044e-04, -4.6480820e-04,\n",
              "                2.5893375e-04, -1.9773468e-04, -3.6987290e-04,\n",
              "               -3.1686202e-04],\n",
              "              [ 2.2875238e-04, -1.1330587e-05,  2.4846941e-04,\n",
              "               -3.8380921e-04, -4.9010850e-08,  2.6402576e-04,\n",
              "                6.6670007e-05, -1.0339217e-04,  2.4285610e-04,\n",
              "               -1.6149040e-04, -3.0530617e-04,  4.1671982e-04,\n",
              "               -2.0463625e-04,  1.2895651e-04,  2.9755849e-04,\n",
              "                2.9682927e-04],\n",
              "              [ 7.7973679e-04,  2.1214318e-04,  5.1670708e-05,\n",
              "               -1.3531931e-03, -1.6536191e-04,  7.7700801e-04,\n",
              "               -1.7047720e-04, -5.0719827e-04,  4.7202595e-04,\n",
              "               -8.4006041e-04, -6.9799833e-04,  8.1419386e-04,\n",
              "               -8.2749128e-04,  7.7049993e-04,  1.0907538e-03,\n",
              "                6.1958097e-04],\n",
              "              [-8.1847236e-04, -2.2145361e-04, -5.8166683e-05,\n",
              "                1.4200546e-03,  1.7277896e-04, -8.1626326e-04,\n",
              "                1.7700484e-04,  5.3164922e-04, -4.9724430e-04,\n",
              "                8.8045001e-04,  7.3433667e-04, -8.5782632e-04,\n",
              "                8.6802617e-04, -8.0727786e-04, -1.1446886e-03,\n",
              "               -6.5233186e-04]], dtype=float32), bias=DeviceArray([-8.3689875e-04, -2.2618525e-04, -6.0935461e-05,\n",
              "               1.4502924e-03,  1.7673311e-04, -8.3452719e-04,\n",
              "               1.8029693e-04,  5.4399384e-04, -5.0956092e-04,\n",
              "               9.0136199e-04,  7.5283251e-04, -8.8100135e-04,\n",
              "               8.8751852e-04, -8.2624331e-04, -1.1707065e-03,\n",
              "              -6.6750858e-04], dtype=float32)), Linear(weight=DeviceArray([[-9.19923186e-04, -5.19948080e-04, -2.70721037e-04,\n",
              "               -4.04970720e-04],\n",
              "              [-8.57037492e-04, -5.06147277e-04, -2.49883276e-04,\n",
              "               -4.13439237e-04],\n",
              "              [ 3.55780590e-04,  2.28552846e-04,  1.02046237e-04,\n",
              "                2.01934483e-04],\n",
              "              [ 5.09839505e-04,  4.00288031e-04,  1.39769632e-04,\n",
              "                4.08761203e-04],\n",
              "              [-4.23263758e-04, -2.02810392e-04, -1.28545333e-04,\n",
              "               -1.25672668e-04],\n",
              "              [-1.73179433e-06,  1.01643614e-04, -1.09863468e-05,\n",
              "                1.69235747e-04],\n",
              "              [-1.76420435e-04, -3.64501029e-05, -5.81531785e-05,\n",
              "                2.68667936e-05],\n",
              "              [-1.09896064e-05, -1.19204633e-05, -2.23994721e-06,\n",
              "               -1.47917308e-05],\n",
              "              [ 7.36877322e-04,  6.66057225e-04,  1.91536034e-04,\n",
              "                7.37615861e-04],\n",
              "              [-2.07508041e-04, -2.63261260e-04, -4.59142611e-05,\n",
              "               -3.33467440e-04],\n",
              "              [ 5.06900251e-05,  6.68335706e-05,  1.15809962e-05,\n",
              "                8.48900527e-05],\n",
              "              [-3.00821848e-04, -1.85677782e-04, -8.77919374e-05,\n",
              "               -1.57317147e-04],\n",
              "              [-4.38857824e-04, -2.47874297e-04, -1.29340449e-04,\n",
              "               -1.92702748e-04],\n",
              "              [-1.94508582e-04, -2.15744600e-04, -4.66993079e-05,\n",
              "               -2.60587782e-04],\n",
              "              [-1.23195350e-05,  9.24747437e-05, -1.40042976e-05,\n",
              "                1.59576535e-04],\n",
              "              [-7.70734623e-04, -4.35858034e-04, -2.27128388e-04,\n",
              "               -3.39275226e-04]], dtype=float32), bias=DeviceArray([-0.05479041, -0.03907277, -0.01533051, -0.03739246], dtype=float32))]), ln1=LayerNorm(gamma=DeviceArray([-7.3315286e-06], dtype=float32), beta=DeviceArray([-5.565146e-05], dtype=float32)), ln2=LayerNorm(gamma=DeviceArray([-5.3135893e-05], dtype=float32), beta=DeviceArray([-0.00017982], dtype=float32)))]))"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grads = jax.grad(loss_decoder_lm)(d, ids, ids_mask)\n",
        "d2 = jax.tree_map(lambda p, g: p - 1 * g, d, grads)  # take a step and compare d2 against d"
      ],
      "metadata": {
        "id": "LQFa5G1kzbbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d.pos_embs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z9W0tYJKzmjF",
        "outputId": "f89e5b1d-9209-40c8-ff2b-f03d8cb9a5d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SinusoidalPositionEmbeddings(weight=DeviceArray([[[ 0.        ,  1.        ,  0.        ,  1.        ],\n",
              "              [ 0.84147096,  0.5403023 ,  0.00999987,  0.99995   ],\n",
              "              [ 0.9092974 , -0.41614684,  0.01999873,  0.9998    ]]],            dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d2.pos_embs  # pos_embs should be frozen and same as d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p5SESWPYzn2e",
        "outputId": "defcbe7d-0a4e-47b8-9d5b-c535ab8ced4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SinusoidalPositionEmbeddings(weight=DeviceArray([[[ 0.        ,  1.        ,  0.        ,  1.        ],\n",
              "              [ 0.84147096,  0.5403023 ,  0.00999987,  0.99995   ],\n",
              "              [ 0.9092974 , -0.41614684,  0.01999873,  0.9998    ]]],            dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# trainable params should have been moved by gradient\n",
        "pprint(jax.tree_map(lambda d1, d2: jnp.abs(d2 - d1).sum(), d, d2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6Y7_FOAzrLJ",
        "outputId": "398b672d-2bbe-4fa4-9d00-a1a30cc89c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DecoderLM(embeddings=Embeddings(weight=DeviceArray(5.462953, dtype=float32)),\n",
            "          pos_embs=SinusoidalPositionEmbeddings(weight=DeviceArray([[[ 0.        ,  1.        ,  0.        ,  1.        ],\n",
            "              [ 0.84147096,  0.5403023 ,  0.00999987,  0.99995   ],\n",
            "              [ 0.9092974 , -0.41614684,  0.01999873,  0.9998    ]]],            dtype=float32)),\n",
            "          layers=[TransformerBlock(mhsa=MultiHeadSelfAttention(to_q=Linear(weight=DeviceArray(1.7719576e-06, dtype=float32),\n",
            "                                                                           bias=DeviceArray(4.520792e-07, dtype=float32)),\n",
            "                                                               to_k=Linear(weight=DeviceArray(4.7171488e-07, dtype=float32),\n",
            "                                                                           bias=DeviceArray(6.320988e-11, dtype=float32)),\n",
            "                                                               to_v=Linear(weight=DeviceArray(0.00270491, dtype=float32),\n",
            "                                                                           bias=DeviceArray(0.00105939, dtype=float32)),\n",
            "                                                               to_out=Linear(weight=DeviceArray(0.01255199, dtype=float32),\n",
            "                                                                             bias=DeviceArray(0.14658615, dtype=float32)),\n",
            "                                                               heads=2,\n",
            "                                                               scale=0.5,\n",
            "                                                               causal=True),\n",
            "                                   mlp=MLP(layers=[Linear(weight=DeviceArray(0.03250986, dtype=float32),\n",
            "                                                          bias=DeviceArray(0.01298697, dtype=float32)),\n",
            "                                                   Linear(weight=DeviceArray(0.02258215, dtype=float32),\n",
            "                                                          bias=DeviceArray(0.14658615, dtype=float32))]),\n",
            "                                   ln1=LayerNorm(gamma=DeviceArray(1.5497208e-06, dtype=float32),\n",
            "                                                 beta=DeviceArray(1.554623e-05, dtype=float32)),\n",
            "                                   ln2=LayerNorm(gamma=DeviceArray(0.00015509, dtype=float32),\n",
            "                                                 beta=DeviceArray(6.63097e-05, dtype=float32))),\n",
            "                  TransformerBlock(mhsa=MultiHeadSelfAttention(to_q=Linear(weight=DeviceArray(5.646725e-07, dtype=float32),\n",
            "                                                                           bias=DeviceArray(1.4817013e-07, dtype=float32)),\n",
            "                                                               to_k=Linear(weight=DeviceArray(2.2805762e-07, dtype=float32),\n",
            "                                                                           bias=DeviceArray(3.7363e-11, dtype=float32)),\n",
            "                                                               to_v=Linear(weight=DeviceArray(0.00461653, dtype=float32),\n",
            "                                                                           bias=DeviceArray(0.00170651, dtype=float32)),\n",
            "                                                               to_out=Linear(weight=DeviceArray(0.00942086, dtype=float32),\n",
            "                                                                             bias=DeviceArray(0.14658615, dtype=float32)),\n",
            "                                                               heads=2,\n",
            "                                                               scale=0.5,\n",
            "                                                               causal=True),\n",
            "                                   mlp=MLP(layers=[Linear(weight=DeviceArray(0.0279907, dtype=float32),\n",
            "                                                          bias=DeviceArray(0.0109066, dtype=float32)),\n",
            "                                                   Linear(weight=DeviceArray(0.0158963, dtype=float32),\n",
            "                                                          bias=DeviceArray(0.14658615, dtype=float32))]),\n",
            "                                   ln1=LayerNorm(gamma=DeviceArray(7.390976e-06, dtype=float32),\n",
            "                                                 beta=DeviceArray(5.565146e-05, dtype=float32)),\n",
            "                                   ln2=LayerNorm(gamma=DeviceArray(5.3167343e-05, dtype=float32),\n",
            "                                                 beta=DeviceArray(0.00017982, dtype=float32)))])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grads.embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt4EY5fD0C4N",
        "outputId": "b2a403db-1e9f-4173-9651-b8c595171dcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embeddings(weight=DeviceArray([[-0.8196529 , -0.5671234 , -0.03178539, -1.3359756 ],\n",
              "             [ 0.67937213,  0.24673419,  0.02402913,  0.9102438 ],\n",
              "             [ 0.1238312 ,  0.30758926,  0.00296418,  0.41365167]],            dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d.embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUAVa2yr0BAG",
        "outputId": "cca3b668-bf2b-438b-d795-12ff315b03b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embeddings(weight=DeviceArray([[ 0.03777524,  0.01509636,  0.01720601,  0.02478568],\n",
              "             [-0.0172825 , -0.01549674,  0.00084439,  0.0017051 ],\n",
              "             [ 0.02888897, -0.01042003,  0.01671507, -0.01324442]],            dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d2.embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdUlPfpsz-bt",
        "outputId": "038386ee-7fde-44c0-fed9-af2eb1c0d74b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embeddings(weight=DeviceArray([[ 0.85742813,  0.5822198 ,  0.0489914 ,  1.3607613 ],\n",
              "             [-0.6966546 , -0.26223093, -0.02318473, -0.9085387 ],\n",
              "             [-0.09494223, -0.3180093 ,  0.01375089, -0.4268961 ]],            dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test LayerNorm"
      ],
      "metadata": {
        "id": "Woz1Iemz04uF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "biased_x = 3 * jax.random.normal(key, (2, 3, 2)) + 7\n",
        "biased_x.shape, biased_x.mean(), biased_x.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STelGzab06bX",
        "outputId": "dbc1a91c-4040-43ac-953c-c6b5c05bc17b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2, 3, 2),\n",
              " DeviceArray(6.656968, dtype=float32),\n",
              " DeviceArray(2.634112, dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mask = jnp.ones((2, 3), dtype=jnp.int32)\n",
        "#mask = mask.at[:, -1:].set(0)\n",
        "ln = LayerNorm.create()\n",
        "debiased_x = ln(biased_x, mask)\n",
        "debiased_x.shape, debiased_x.mean(), debiased_x.std()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7NrlHUk0_wW",
        "outputId": "46689d2e-c32a-4e86-f787-fe75dc1f2e38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2, 3, 2),\n",
              " DeviceArray(-9.934108e-08, dtype=float32),\n",
              " DeviceArray(0.9999989, dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optimizers"
      ],
      "metadata": {
        "id": "jyVQOF4F1WOa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class SGDOptimizer:\n",
        "  lr: float\n",
        "\n",
        "  @staticmethod\n",
        "  def create(params, lr=0.001):\n",
        "    return SGDOptimizer(lr=lr)\n",
        "\n",
        "  def update(self, params, grads, lr=None):\n",
        "    if lr is None:\n",
        "      lr = self.lr\n",
        "\n",
        "    def apply_grad(p, g):\n",
        "      return p - lr * g\n",
        "    return jax.tree_map(apply_grad, params, grads)\n",
        "\n",
        "  @staticmethod\n",
        "  def _flatten(self):\n",
        "    return ((), (self.lr,))\n",
        "\n",
        "  @staticmethod\n",
        "  def _unflatten(aux_data, flat_contents):\n",
        "    lr, = aux_data\n",
        "    return SGDOptimizer(lr=lr)\n",
        "\n",
        "jax.tree_util.register_pytree_node(SGDOptimizer,\n",
        "                                   SGDOptimizer._flatten,\n",
        "                                   SGDOptimizer._unflatten)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class AdamOptimizer:\n",
        "  m: Any  # pytree\n",
        "  v: Any  # pytree\n",
        "  lr: jax.Array  # shape [1]\n",
        "  betas: jax.Array # shape [2]\n",
        "  eps: jax.Array  # shape [1]\n",
        "\n",
        "  @staticmethod\n",
        "  def create(params, lr=0.001, betas=(0.9, 0.999), eps=1e-8):\n",
        "    m = jax.tree_map(lambda x: jnp.zeros_like(x), params)\n",
        "    v = jax.tree_map(lambda x: jnp.zeros_like(x), params)\n",
        "    return AdamOptimizer(m=m, v=v,\n",
        "                         lr=jnp.array([lr], dtype=jnp.float32),\n",
        "                         betas=jnp.array(betas, dtype=jnp.float32),\n",
        "                         eps=jnp.array([eps], dtype=jnp.float32))\n",
        "\n",
        "  def update(self, params, grads, lr=None):\n",
        "    if lr is None:\n",
        "      lr = self.lr\n",
        "\n",
        "    def _update_m(m, g):\n",
        "      return self.betas[0] * m + (1 - self.betas[0]) * g\n",
        "    def _update_v(v, g):\n",
        "      return self.betas[1] * v + (1 - self.betas[1]) * g**2\n",
        "    self.m = jax.tree_map(_update_m, self.m, grads)\n",
        "    self.v = jax.tree_map(_update_v, self.v, grads)\n",
        "\n",
        "    def _compute_m_hat(m):\n",
        "      return m / (1 - self.betas[0])\n",
        "    def _compute_v_hat(v):\n",
        "      return v / (1 - self.betas[1])\n",
        "    m_hat = jax.tree_map(_compute_m_hat, self.m)\n",
        "    v_hat = jax.tree_map(_compute_v_hat, self.v)\n",
        "\n",
        "    def _update_params(p, m_hat, v_hat):\n",
        "      return p - lr * m_hat / (v_hat ** 0.5 + self.eps)\n",
        "    params_new = jax.tree_map(_update_params, params, m_hat, v_hat)\n",
        "    return params_new\n",
        "\n",
        "  @staticmethod\n",
        "  def _flatten(self):\n",
        "    return ((self.m, self.v),  # trainable\n",
        "            (self.lr, self.betas, self.eps))  # non-trainable\n",
        "\n",
        "  @staticmethod\n",
        "  def _unflatten(aux_data, flat_contents):\n",
        "    m, v = flat_contents\n",
        "    lr, betas, eps = aux_data\n",
        "    return AdamOptimizer(m=m, v=v, lr=lr, betas=betas, eps=eps)\n",
        "\n",
        "jax.tree_util.register_pytree_node(AdamOptimizer, AdamOptimizer._flatten,\n",
        "                                   AdamOptimizer._unflatten)\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class CosineDecayLR:\n",
        "  optimizer: Any  # *Optimizer\n",
        "  lr: jax.Array  # shape [1]\n",
        "  total_steps: int\n",
        "  warmup_steps: int\n",
        "  curr_lr: jax.Array = field(default_factory=lambda: jnp.array([0.], dtype=jnp.float32))\n",
        "  curr_step: jax.Array = field(default_factory=lambda: jnp.array([0], dtype=jnp.int32))\n",
        "\n",
        "  def update(self, params, grads):\n",
        "    self.step()\n",
        "    return self.optimizer.update(params, grads, self.curr_lr)\n",
        "\n",
        "  def step(self):\n",
        "    self.curr_step = jnp.minimum(self.curr_step + 1, self.total_steps)\n",
        "    lr_during_ramp = self.lr * self.curr_step / self.warmup_steps\n",
        "    decay_frac = (self.curr_step - self.warmup_steps) / (self.total_steps - self.warmup_steps)\n",
        "    lr_during_decay = self.lr * 0.5 * (jnp.cos(decay_frac * jnp.pi) + 1)\n",
        "    in_ramp = self.curr_step < self.warmup_steps\n",
        "    self.curr_lr = in_ramp * lr_during_ramp + (1 - in_ramp) * lr_during_decay\n",
        "\n",
        "\n",
        "def clip_grad_norm(grads: Any, max_norm: float):\n",
        "  norms = jax.tree_map(jnp.linalg.norm, grads)\n",
        "  def clip(x, norm):\n",
        "    return jnp.where(norm <= max_norm, x, x * max_norm / (norm + 1e-6))\n",
        "  return jax.tree_map(clip, grads, norms)"
      ],
      "metadata": {
        "id": "o6DzHkZg1XPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test SGD"
      ],
      "metadata": {
        "id": "aZJSrNcx5tHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "val, grads = jax.value_and_grad(loss_decoder_lm)(d, ids, ids_mask)"
      ],
      "metadata": {
        "id": "-H0_yw-25t5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grads.embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "857CDdUs6Okh",
        "outputId": "e22d22df-c295-4db9-f8be-ea676663fe66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embeddings(weight=DeviceArray([[-0.8196529 , -0.5671234 , -0.03178539, -1.3359756 ],\n",
              "             [ 0.67937213,  0.24673419,  0.02402913,  0.9102438 ],\n",
              "             [ 0.1238312 ,  0.30758926,  0.00296418,  0.41365167]],            dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d.embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5z9l3M8a5yef",
        "outputId": "8ca2f199-14f8-4e52-9626-91472e0613b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embeddings(weight=DeviceArray([[ 0.03777524,  0.01509636,  0.01720601,  0.02478568],\n",
              "             [-0.0172825 , -0.01549674,  0.00084439,  0.0017051 ],\n",
              "             [ 0.02888897, -0.01042003,  0.01671507, -0.01324442]],            dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_test = SGDOptimizer.create(params=d, lr=0.1)\n",
        "d_new = jax.jit(sgd_test.update)(d, grads)\n",
        "d_new.embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2NdL6dWD5_L1",
        "outputId": "4693ede4-19fb-4f49-c0dd-d6aecf919fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embeddings(weight=DeviceArray([[ 0.11974053,  0.0718087 ,  0.02038455,  0.15838325],\n",
              "             [-0.08521973, -0.04017016, -0.00155852, -0.08931928],\n",
              "             [ 0.01650585, -0.04117896,  0.01641865, -0.05460959]],            dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test Adam"
      ],
      "metadata": {
        "id": "lWv4Dr6T6TNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "adam_test = AdamOptimizer.create(params=d, lr=0.1)\n",
        "d_new = jax.jit(adam_test.update)(d, grads)\n",
        "d_new.embeddings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dUY73uV57zB",
        "outputId": "f99976fb-e583-4d7e-f6cc-44e25fd905e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embeddings(weight=DeviceArray([[ 0.13777524,  0.11509636,  0.11720599,  0.12478568],\n",
              "             [-0.11728252, -0.11549675, -0.09915557, -0.09829491],\n",
              "             [-0.07111105, -0.11042003, -0.08328459, -0.11324443]],            dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test CosineDecayLR"
      ],
      "metadata": {
        "id": "DayH1OEW6s6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@jax.jit\n",
        "def test_cosine_decay_lr():\n",
        "  cd = CosineDecayLR(optimizer=None, lr=1.0, total_steps=110, warmup_steps=10)\n",
        "  for i in range(15):\n",
        "    print(i, cd.curr_lr)\n",
        "    cd.step()\n",
        "\n",
        "  for i in range(15, 100):\n",
        "    cd.step()\n",
        "\n",
        "  for i in range(100, 111):\n",
        "    print(i, cd.curr_lr)\n",
        "    cd.step()"
      ],
      "metadata": {
        "id": "76hoR-9n6t4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_cosine_decay_lr()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EVaEQxXU6_ug",
        "outputId": "e2fc3f95-b5c6-45c2-8c18-fa2b282a5f43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 [0.]\n",
            "1 [0.1]\n",
            "2 [0.2]\n",
            "3 [0.3]\n",
            "4 [0.4]\n",
            "5 [0.5]\n",
            "6 [0.6]\n",
            "7 [0.7]\n",
            "8 [0.8]\n",
            "9 [0.90000004]\n",
            "10 [1.]\n",
            "11 [0.99975324]\n",
            "12 [0.99901336]\n",
            "13 [0.997781]\n",
            "14 [0.9960574]\n",
            "100 [0.02447173]\n",
            "101 [0.01985314]\n",
            "102 [0.01570839]\n",
            "103 [0.0120416]\n",
            "104 [0.00885636]\n",
            "105 [0.00615582]\n",
            "106 [0.00394264]\n",
            "107 [0.00221902]\n",
            "108 [0.00098664]\n",
            "109 [0.00024673]\n",
            "110 [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test ClipGradNorm"
      ],
      "metadata": {
        "id": "TKUPMT267L6m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jax.tree_map(jnp.linalg.norm, grads)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6JVErlf7LjY",
        "outputId": "173dd672-6df0-4ced-ad78-5df6dd962595"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecoderLM(embeddings=Embeddings(weight=DeviceArray(2.1004543, dtype=float32)), pos_embs=SinusoidalPositionEmbeddings(weight=DeviceArray([[[ 0.        ,  1.        ,  0.        ,  1.        ],\n",
              "              [ 0.84147096,  0.5403023 ,  0.00999987,  0.99995   ],\n",
              "              [ 0.9092974 , -0.41614684,  0.01999873,  0.9998    ]]],            dtype=float32)), layers=[TransformerBlock(mhsa=MultiHeadSelfAttention(to_q=Linear(weight=DeviceArray(4.8988517e-07, dtype=float32), bias=DeviceArray(2.4523015e-07, dtype=float32)), to_k=Linear(weight=DeviceArray(1.842191e-07, dtype=float32), bias=DeviceArray(4.678597e-11, dtype=float32)), to_v=Linear(weight=DeviceArray(0.00094585, dtype=float32), bias=DeviceArray(0.00064803, dtype=float32)), to_out=Linear(weight=DeviceArray(0.00346797, dtype=float32), bias=DeviceArray(0.07854329, dtype=float32)), heads=2, scale=0.5, causal=True), mlp=MLP(layers=[Linear(weight=DeviceArray(0.0056897, dtype=float32), bias=DeviceArray(0.00402003, dtype=float32)), Linear(weight=DeviceArray(0.00411666, dtype=float32), bias=DeviceArray(0.07859718, dtype=float32))]), ln1=LayerNorm(gamma=DeviceArray(1.5493649e-06, dtype=float32), beta=DeviceArray(1.5546231e-05, dtype=float32)), ln2=LayerNorm(gamma=DeviceArray(0.00015508, dtype=float32), beta=DeviceArray(6.63097e-05, dtype=float32))), TransformerBlock(mhsa=MultiHeadSelfAttention(to_q=Linear(weight=DeviceArray(2.0917373e-07, dtype=float32), bias=DeviceArray(1.0866429e-07, dtype=float32)), to_k=Linear(weight=DeviceArray(1.400507e-07, dtype=float32), bias=DeviceArray(2.5769713e-11, dtype=float32)), to_v=Linear(weight=DeviceArray(0.00153629, dtype=float32), bias=DeviceArray(0.001047, dtype=float32)), to_out=Linear(weight=DeviceArray(0.0035295, dtype=float32), bias=DeviceArray(0.07860867, dtype=float32)), heads=2, scale=0.5, causal=True), mlp=MLP(layers=[Linear(weight=DeviceArray(0.00443217, dtype=float32), bias=DeviceArray(0.00310101, dtype=float32)), Linear(weight=DeviceArray(0.00267503, dtype=float32), bias=DeviceArray(0.07849771, dtype=float32))]), ln1=LayerNorm(gamma=DeviceArray(7.3315286e-06, dtype=float32), beta=DeviceArray(5.565146e-05, dtype=float32)), ln2=LayerNorm(gamma=DeviceArray(5.313589e-05, dtype=float32), beta=DeviceArray(0.00017982, dtype=float32)))])"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grads_clipped = clip_grad_norm(grads, max_norm=0.01)"
      ],
      "metadata": {
        "id": "oosYGQli7RJ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "jax.tree_map(jnp.linalg.norm, grads_clipped)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGEA92Q07V6c",
        "outputId": "78741fff-4aae-4cfd-9cbe-8db61e2e10c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DecoderLM(embeddings=Embeddings(weight=DeviceArray(0.01, dtype=float32)), pos_embs=SinusoidalPositionEmbeddings(weight=DeviceArray([[[ 0.        ,  1.        ,  0.        ,  1.        ],\n",
              "              [ 0.84147096,  0.5403023 ,  0.00999987,  0.99995   ],\n",
              "              [ 0.9092974 , -0.41614684,  0.01999873,  0.9998    ]]],            dtype=float32)), layers=[TransformerBlock(mhsa=MultiHeadSelfAttention(to_q=Linear(weight=DeviceArray(4.8988517e-07, dtype=float32), bias=DeviceArray(2.4523015e-07, dtype=float32)), to_k=Linear(weight=DeviceArray(1.842191e-07, dtype=float32), bias=DeviceArray(4.678597e-11, dtype=float32)), to_v=Linear(weight=DeviceArray(0.00094585, dtype=float32), bias=DeviceArray(0.00064803, dtype=float32)), to_out=Linear(weight=DeviceArray(0.00346797, dtype=float32), bias=DeviceArray(0.00999987, dtype=float32)), heads=2, scale=0.5, causal=True), mlp=MLP(layers=[Linear(weight=DeviceArray(0.0056897, dtype=float32), bias=DeviceArray(0.00402003, dtype=float32)), Linear(weight=DeviceArray(0.00411666, dtype=float32), bias=DeviceArray(0.00999987, dtype=float32))]), ln1=LayerNorm(gamma=DeviceArray(1.5493649e-06, dtype=float32), beta=DeviceArray(1.5546231e-05, dtype=float32)), ln2=LayerNorm(gamma=DeviceArray(0.00015508, dtype=float32), beta=DeviceArray(6.63097e-05, dtype=float32))), TransformerBlock(mhsa=MultiHeadSelfAttention(to_q=Linear(weight=DeviceArray(2.0917373e-07, dtype=float32), bias=DeviceArray(1.0866429e-07, dtype=float32)), to_k=Linear(weight=DeviceArray(1.400507e-07, dtype=float32), bias=DeviceArray(2.5769713e-11, dtype=float32)), to_v=Linear(weight=DeviceArray(0.00153629, dtype=float32), bias=DeviceArray(0.001047, dtype=float32)), to_out=Linear(weight=DeviceArray(0.0035295, dtype=float32), bias=DeviceArray(0.00999987, dtype=float32)), heads=2, scale=0.5, causal=True), mlp=MLP(layers=[Linear(weight=DeviceArray(0.00443217, dtype=float32), bias=DeviceArray(0.00310101, dtype=float32)), Linear(weight=DeviceArray(0.00267503, dtype=float32), bias=DeviceArray(0.00999987, dtype=float32))]), ln1=LayerNorm(gamma=DeviceArray(7.3315286e-06, dtype=float32), beta=DeviceArray(5.565146e-05, dtype=float32)), ln2=LayerNorm(gamma=DeviceArray(5.313589e-05, dtype=float32), beta=DeviceArray(0.00017982, dtype=float32)))])"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decoding"
      ],
      "metadata": {
        "id": "50sqbimq-UFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: make this batched\n",
        "# TODO: replace use_argmax with temperature\n",
        "# TODO: make this jittable\n",
        "def sample(model, prompt=None, prompt_ids=None, max_tokens=30, print_loop=False,\n",
        "           use_argmax=False):\n",
        "  assert prompt is not None or prompt_ids is not None\n",
        "  if prompt:\n",
        "    ids = jnp.array(tokenizer_encode(prompt).numpy())\n",
        "  else:\n",
        "    ids = jnp.array([prompt_ids])\n",
        "  start_idx = ids.shape[1]\n",
        "  for i in range(max_tokens):\n",
        "    padded_ids = jnp.zeros((1, MAX_SEQ_LEN), dtype=jnp.int32)\n",
        "    padded_ids = padded_ids.at[:, :ids.shape[1]].set(ids)\n",
        "    mask = jnp.zeros_like(padded_ids)\n",
        "    mask = mask.at[:, ids.shape[1]].set(1)\n",
        "    logits = model(padded_ids, mask)  # [b, t, v]\n",
        "    logits = logits[0, start_idx + i - 1, :]  # [v]\n",
        "    probs = jnp.exp(logits).astype(jnp.float64)\n",
        "    if use_argmax:\n",
        "      token = jnp.argmax(logits, axis=-1)[None, None]\n",
        "    else:  # sample from distribution\n",
        "      probs /= jnp.sum(probs)  # w/o this, sum is ~1, but not exactly\n",
        "      token = np.random.choice(np.arange(len(probs)), size=(1, 1), p=probs)\n",
        "    ids = jnp.concatenate([ids, token], axis=1)\n",
        "    if print_loop:\n",
        "      print(tokenizer_decode(ids))\n",
        "  output = tokenizer_decode(ids)\n",
        "  return output"
      ],
      "metadata": {
        "id": "hhHmFR8T86UC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss"
      ],
      "metadata": {
        "id": "gO5jMqTZBp--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def compute_loss(model, batch):\n",
        "  ids, ids_target, mask = batch\n",
        "  attn_mask, targets_mask = mask[:, :-1], mask[:, 1:]\n",
        "  logits = model(ids, attn_mask)\n",
        "  logits = rearrange(logits, 'b t v -> (b t) v')\n",
        "  ids_target = ids_target.flatten()\n",
        "  targets_mask = targets_mask.flatten()\n",
        "  example_losses = -logits[jnp.arange(len(ids_target)), ids_target]\n",
        "  loss = jnp.sum(example_losses * targets_mask) / jnp.sum(targets_mask)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "2q0zVf3dBrKq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## test compute_loss"
      ],
      "metadata": {
        "id": "OH9dTQ1LBDRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = DecoderLM.create(key, vocab_size=3, num_layers=2, dim=4, heads=2, max_seq_len=3)\n",
        "ids_batch = np.array(\n",
        "    [[0, 1, 2, 1],\n",
        "     [2, 0, 1, 2]])\n",
        "ids_input, ids_target = ids_batch[:, :-1], ids_batch[:, 1:]\n",
        "mask = jnp.array([[1, 1, 1, 0], [1, 1, 1, 0]])\n",
        "\n",
        "print(compute_loss(model, (ids_input, ids_target, mask)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ76IJr6BFxw",
        "outputId": "6e612f97-7b2e-40ae-c34a-a691e9335868"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.1060945\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train loop (data-parallel)"
      ],
      "metadata": {
        "id": "XDqDodFa7gUu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.sharding\n",
        "from jax.experimental import mesh_utils\n",
        "\n",
        "devices = mesh_utils.create_device_mesh((N_DEVICES,))\n",
        "sharding = jax.sharding.PositionalSharding(devices)"
      ],
      "metadata": {
        "id": "7iGLHLgK7jRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@jax.jit\n",
        "def train_on_batch(model, batch, optimizer):\n",
        "  loss, grads = jax.value_and_grad(compute_loss)(model, batch)\n",
        "  #id_print(grads.layers[0].bias.shape, tap_with_device=True, device_index=0)\n",
        "  #id_print(grads.layers[0].bias[0], tap_with_device=True, device_index=1)\n",
        "\n",
        "  grads = clip_grad_norm(grads, max_norm=1)\n",
        "  model = optimizer.update(model, grads)  # optimizer is mutated, so have to return it\n",
        "  return model, optimizer, loss\n",
        "\n",
        "\n",
        "def train_parallel(model, train_dl, valid_dl, sharding, optimizer, steps,\n",
        "                   n_decode=4, decode_every_steps=0):\n",
        "  model = jax.device_put(model, sharding.replicate())\n",
        "  optimizer = jax.device_put(optimizer, sharding.replicate())\n",
        "  losses = []\n",
        "  print('ground truth')\n",
        "  for ids in one_batch_unique_ids[:n_decode]:\n",
        "    print(tokenizer_decode(ids)[0])\n",
        "  print('-' * 80)\n",
        "\n",
        "  try:\n",
        "    for i, batch in enumerate(train_dl):\n",
        "      batch = jax.device_put(batch, sharding.reshape(N_DEVICES, 1))\n",
        "      model, optimizer, loss = train_on_batch(model, batch, optimizer)\n",
        "      if i % 10 == 0:\n",
        "        losses.append(loss)\n",
        "        print(f'step {i} lr: {optimizer.curr_lr[0]:0.6g} loss: {loss}')\n",
        "\n",
        "      if decode_every_steps > 0 and i % decode_every_steps == 0:\n",
        "        for ids in one_batch_unique_ids[:n_decode]:\n",
        "          ids = ids[:5]\n",
        "          text = sample(model, prompt_ids=ids, max_tokens=15)[0]\n",
        "          print(text)\n",
        "\n",
        "      if i == steps:\n",
        "        break\n",
        "  except KeyboardInterrupt:\n",
        "    pass\n",
        "  return model, optimizer, losses"
      ],
      "metadata": {
        "id": "KN3RcoER-s4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "9O_khrtVB8oT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jax.config.update('jax_default_matmul_precision', 'bfloat16')\n",
        "#jax.config.update('jax_default_matmul_precision', 'float32')"
      ],
      "metadata": {
        "id": "8lPc6vJAB9Em"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DecoderLM.create(key, vocab_size=VOCAB_SIZE, num_layers=12, dim=768,\n",
        "                         heads=12, max_seq_len=MAX_SEQ_LEN)"
      ],
      "metadata": {
        "id": "HgXA0WeACDFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 3e-4\n",
        "TOTAL_STEPS = 100_000\n",
        "WARMUP_STEPS = 2000\n",
        "DECODE_EVERY_STEPS = 1000\n",
        "\n",
        "#optimizer = SGDOptimizer.create(params=model, lr=LR)\n",
        "optimizer = AdamOptimizer.create(params=model, lr=LR)\n",
        "optimizer = CosineDecayLR(optimizer=optimizer,\n",
        "                          lr=jnp.array(LR),  # Pathways requires everything to be wrapped as jax.Array\n",
        "                          total_steps=jnp.array(TOTAL_STEPS),\n",
        "                          warmup_steps=jnp.array(WARMUP_STEPS))"
      ],
      "metadata": {
        "id": "-hzbuBjgCPnb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Profile to see check TPU utilization and see if we're input-bound\n",
        "#%xprof model, optimizer, losses = train_parallel(model, dataloader_train, None, sharding, optimizer, steps=200)"
      ],
      "metadata": {
        "id": "kLUgTqySCs-K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, optimizer, losses = train_parallel(\n",
        "    model, dataloader_train, None, sharding, optimizer,\n",
        "    steps=TOTAL_STEPS, decode_every_steps=DECODE_EVERY_STEPS,\n",
        ")"
      ],
      "metadata": {
        "id": "U2uBfNnVC3Q_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run model on examples"
      ],
      "metadata": {
        "id": "pcLCZWvEDPwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ex_id = 2\n",
        "one_batch_unique_ids[ex_id, ...], tokenizer_decode(one_batch_unique_ids[ex_id, ...])"
      ],
      "metadata": {
        "id": "Nr2MtP1mDS8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample(model, prompt_ids=[1215, 15355, 1355, 23936, 286, 8099], print_loop=True)"
      ],
      "metadata": {
        "id": "sLIvhSllDeR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Debug"
      ],
      "metadata": {
        "id": "e3b7PgsdDkT2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Total device ram usage"
      ],
      "metadata": {
        "id": "VuQT3GUmDm8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import humanize\n",
        "\n",
        "fmt_size = partial(humanize.naturalsize, binary=True)\n",
        "\n",
        "def print_memory(device):\n",
        "  stats = device.memory_stats()\n",
        "  print(stats)\n",
        "  used = stats['bytes_in_use']\n",
        "  limit = stats['bytes_limit']\n",
        "  print(f'Using {fmt_size(used)} / {fmt_size(limit)} ({used/miti:%}) on {device}')"
      ],
      "metadata": {
        "id": "4JudMYZTDk6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_memory(jax.local_devices()[0])"
      ],
      "metadata": {
        "id": "F9AINst-D81b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_memory(jax.local_devices()[1])"
      ],
      "metadata": {
        "id": "zYyXx867D_Xl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clear memory"
      ],
      "metadata": {
        "id": "kAjz6O_VEFFt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def jax_delete_live_arrays():\n",
        "  for x in jax.live_arrays():\n",
        "    x.delete()\n",
        "\n",
        "if False:\n",
        "  jax.clear_caches()\n",
        "  jax_delete_live_arrays()"
      ],
      "metadata": {
        "id": "ZvQkhvdnEGVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checkpointing\n",
        "\n",
        "https://jax.readthedocs.io/en/latest/notebooks/autodiff_remat.html"
      ],
      "metadata": {
        "id": "d47SyL5cEOa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jax.ad_checkpoint\n",
        "jax.ad_checkpoint.print_saved_residuals(compute_loss, model, batch)"
      ],
      "metadata": {
        "id": "mBpSHe2oEmSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## print_fwd_bwd"
      ],
      "metadata": {
        "id": "PsfE3UEGEijW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from jax.tree_util import tree_flatten, tree_unflatten\n",
        "\n",
        "from rich.console import Console\n",
        "from rich.table import Table\n",
        "import rich.text\n",
        "\n",
        "def print_fwd_bwd(f, *args, **kwargs) -> None:\n",
        "  args, in_tree = tree_flatten((args, kwargs))\n",
        "\n",
        "  def f_(*args):\n",
        "    args, kwargs = tree_unflatten(in_tree, args)\n",
        "    return f(*args, **kwargs)\n",
        "\n",
        "  fwd = jax.make_jaxpr(lambda *args: jax.vjp(f_, *args))(*args).jaxpr\n",
        "\n",
        "  y, f_vjp = jax.vjp(f_, *args)\n",
        "  res, in_tree = tree_flatten(f_vjp)\n",
        "\n",
        "  def g_(*args):\n",
        "    *res, y = args\n",
        "    f_vjp = tree_unflatten(in_tree, res)\n",
        "    return f_vjp(y)\n",
        "\n",
        "  bwd = jax.make_jaxpr(g_)(*res, y).jaxpr\n",
        "\n",
        "  table = Table(show_header=False, show_lines=True, padding=(1, 2, 0, 2), box=None)\n",
        "  table.add_row(\"[bold green]forward computation:\",\n",
        "                \"[bold green]backward computation:\")\n",
        "  table.add_row(rich.text.Text.from_ansi(str(fwd)),\n",
        "                rich.text.Text.from_ansi(str(bwd)))\n",
        "  console = Console(width=240, force_jupyter=True)\n",
        "  console.print(table)\n",
        "\n",
        "def _renderable_repr(self):\n",
        "  return self.html\n",
        "rich.jupyter.JupyterRenderable._repr_html = _renderable_repr"
      ],
      "metadata": {
        "id": "rwJdh6-kEkp7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_fwd_bwd(compute_loss, model, batch)"
      ],
      "metadata": {
        "id": "ZR88rD-0FoD5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}