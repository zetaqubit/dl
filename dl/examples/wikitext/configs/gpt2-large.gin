model_name = 'gpt2-large'

batch_size = 8
max_seq_len = 256
learning_rate = 1e-4
train_steps = 100_000
log_steps = 500
eval_interval = 1000
eval_steps = 1
ckpt_steps = 20_000

GPT.n_layers = 36
GPT.dim = 1280
GPT.max_seq_len = %max_seq_len
GPT.vocab = 50257

AutoregressiveModel.net = @GPT()
AutoregressiveModel.ignore_index = 50256

SelfAttention.heads = 20
